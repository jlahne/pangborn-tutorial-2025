[["index.html", "Publication-quality data visualizations using the R tidyverse Introduction and welcome Introductions Today’s agenda How we’re going to run PSA: not-knowing is normal!", " Publication-quality data visualizations using the R tidyverse Jacob Lahne1 Leah Hamilton2 Introduction and welcome Welcome to the Sensometrics Workshop “Publication-quality data visualizations using the R tidyverse”! This workshop is going to be conducted not using slides, but through livecoding. That means we are going to run code lines in the console or highlight and run code in scripts and other files. It is also an opportunity and encouragement for you to follow along. Along with introducing ourselves for today’s workshop, we’re going to discuss a bit about how that will work here. Introductions Leah Hamilton, PhD Leah Hamilton is an Assistant Professor of Sensory &amp; Flavor Science at Virginia State University, in the US. Her primary research interest is flavor language, including the ways that people talk about flavors using their own words in different contexts. In her new position at Virginia State University, she’ll be working closely with plant breeders and agricultural scientists to develop sensory-driven specialty crops and support the work of small and underprivileged farmers in the mid-Atlantic US. Jacob Lahne, PhD Jacob Lahne is an Associate Professor of Food Science &amp; Technology at Virginia Tech, in the United States. He runs the Virginia Tech Sensory Evaluation Laboratory, as well as teaching courses in data analytics and coding for food-science research. His main research focuses are sensory data-analysis methodologies and investigating the sensory properties of fermented and distilled foods and beverages. Today’s agenda Today’s workshop is going to take ~3 hours, and we’ll be covering the following material: Importing Data Reading tabular data Checking data fidelity Basics of Tidy Data Analysis Intro to ggplot2 Other Packages &amp; Extras Adding layers and geoms (e.g., ggrepel) Plot-builders (e.g., factoextra) Combining plots Fine-Tuning Publication-Quality ggplots Exporting plots Formatting text Ordering categorical variables How we’re going to run This workshop is going to be run with livecoding, as noted above. This means we won’t be using slides or a prepared video, but running through code step by step to show how these tools are used in practice. We encourage you to also follow along with livecoding, because the best way to learn coding is to actually do it. Recommended approach for livecoding We recommend that you download the pre-made archive of code and data from the workshop github repo. This archive, when unzipped, will have a folder structure and a .Rproj file. We recommend that you close out RStudio, unzip the archive, and double click the .Rproj file in that folder, which will open a new session of RStudio with proper settings (like the home directory) for the files for this workshop. In that folder, you will find a data/ folder with the necessary data for the workshop, and a script named sensometrics-all-code.R. This latter file contains all of the code demonstrated in this workshop for your future reference. You can also follow along with the code at the workshop’s page hosted on github.io (which you’re reading right now), and which will remain available after this workshop. Once you’re in RStudio, go to the File &gt; New File &gt; R Script menu to open a new script. Scrips are basically workbooks for you to store sequential lines of code to be run in the Console. It is where you can livecode along! Even though we are giving you all of the code you need right now, you will learn a lot more if you actively write out the code to follow along, rather than just running the entire code file. The Console is the place to run code that is short and easy to type, or that you’re experimenting with. It will allow you to write a single line of code, and after you hit return, R will execute the command. This is great for “interactive programming”, but it isn’t so great for building up a complex workflow, or for following along with this workshop! You can write multiple lines of code in your R Script, then execute each one in any order (although keeping a logical sequence from top to bottom will help you keep track of what you’re doing). In an R script, everything is expected to be valid R code. You can&#39;t write this in an R script because it is plain text. This will cause an error. # If you want to write text or notes to yourself, use the &quot;#&quot; symbol at the start of # every line to &quot;comment&quot; out that line. You can also put &quot;#&quot; in the middle of # a line in order to add a comment - everything after will be ignored. 1 + 1 # this is valid R syntax print(&quot;hello world&quot;) # this is also valid R syntax To run code from your R script, put your cursor on the line you want to run and either hit the run button with the green arrow at the top left or (my preferred method) type cmd + return (on Mac) or ctrl + return (on PC). Dealing with errors Coding means making mistakes. This is fine–as you will surely see today, we will make a ton of trivial errors and have to fix things on the fly. If you run into trouble, try looking carefully at what you’ve done and see if you can see what went wrong. You can also make use of the help files in R. You can always get help on a particular function by typing ?&lt;search term&gt;, which will make the help documentation for whatever you’ve searched for appear. For example, try typing the following to get help for the sessionInfo() command: ?sessionInfo But what if you don’t know what to search for? By typing ??&lt;search term&gt; you will search all help files for the search term. R will return a list of matching articles to you in the help pane. This is considerably slower, since it’s searching hundreds or thousands of text files. Try typing ??install into your console to see how this works. You will notice that there are two types of results in the help list for install. The help pages should be familiar. But what are “vignettes”? Try clicking on one to find out. Vignettes are formatted, conversational walkthroughs that are increasingly common (and helpful!) in R packages. Rather than explaining a single function they usually explain some aspect of a package, and how to use it. And, even better for our purposes, they are written in R Markdown. Click the “source” link next to the vignette name in order to see how the author wrote it in R Markdown. This is a great way to learn new tricks. While you can find vignettes as we just did, a better way is to use the function browseVignettes(). This opens a web browser window that lists all vignettes installed on your computer. You can then use cmd/ctrl + F to search using terms in the web browser and quickly find package names, function names, or topics you are looking for. PSA: not-knowing is normal! Above, I mentioned “help files”. How do we get help when we (inevitably) run into problems in R? There are a couple steps you will find helpful in the future: Look up the help file for whatever you’re doing. Do this by using the syntax ?&lt;search item&gt; (for example ?c gets help on the vector command) as a shortcut on the console. Search the help files for a term you think is related. Can’t remember the command for making a sequence of integers? Go to the “Help” pane in RStudio and search in the search box for “sequence”. See if some of the top results get you what you need. The internet. Seriously. I am not kidding even a little bit. R has one of the most active and (surprisingly) helpful user communities I’ve ever encountered. Try going to google and searching for “How do I make a sequence of numbers in R?” You will find quite a bit of useful help. I find the following sites particularly helpful Stack Overflow Cross Validated/Stack Exchange Seriously, Google will get you most of the way to helpful answers for many basic R questions. We may come back to this, but I want to emphasize that looking up help is normal. I do it all the time. Learning to ask questions in helpful ways, how to quickly parse the information you find, and how to slightly alter the answers to suit your particular situation are key skills. Getting Help If you get stuck and can’t figure out what went wrong, we are here to help! Because we have 2 instructors for this workshop, one of us is available to help at any time. When you run into trouble, please raise your hand. We’ll be keeping an eye out, and whichever instructor isn’t livecoding will come to help you. If your issue is a common one or something we think is worth noting, don’t worry–we’ll make time to discuss it! Virginia Tech, jlahne@vt.edu↩︎ Virginia State University, lhamilton@vsu.edu↩︎ "],["a-crash-course-in-r-and-rstudio.html", "1 A crash course in R and RStudio 1.1 R vs RStudio 1.2 The parts of RStudio 1.3 Extending R with packages 1.4 Making R do stuff 1.5 Livecoding along 1.6 Summary and next steps", " 1 A crash course in R and RStudio In this section, we’re going to very briefly go over the basics of R. This is meant to get everyone on the same page. If you’ve done the pre-work we described on the tutorial github repo, this will hopefully be pretty familiar! 1.1 R vs RStudio In this workshop we are going to be learning the basics of coding for text analysis in R, but we will be using the RStudio interface/IDE! Why am I using R for this workshop? And why do we need this extra layer of program to deal with it? 1.1.1 What is R? R is a programming language that was built for statistical and numerical analysis. It is not unique in these spaces–most of you are probably familiar with a program like SAS, SPSS, Unscrambler, XLSTAT, JMP, etc. Unlike these, R is free and open-source. This has two main consequences: R is constantly being extended to do new, useful things because there is a vibrant community of analysts developing tools for it, and the barrier to entry is very low. R doesn’t have a fixed set of tasks that it can accomplish, and, in fact, I generally haven’t found a data-analysis task I needed to do that I couldn’t in R. Because it’s a programming language, R isn’t point-and-click–today we’re going to be typing commands into the console, hitting, enter, making errors, and repeating. But this is a good thing! The power and flexibility of R (and its ability to do most of the things we want) come from the fact that it is a programming language. While learning to use R can seem intimidating, the effort to do so will give you a much more powerful suite of tools than the more limited point-and-click alternatives. R is built for research programming (data analysis), rather than for production programming. The only other alternative that is as widely supported in the research community is Python, but–honesty time here–I have never learned Python very well, and so we are learning R. And, in addition, Python doesn’t have as good an Interactive Development Environment (IDE, explained further below) as RStudio! If you open your R.exe/R application, you’ll see something like this: The R graphical console You can also work with R from a shell interface, but I will not be discussing this approach in this workshop. 1.1.2 Great, why are we using RStudio then? RStudio is an “Interactive Development Environment” (IDE) for working with R. Without going into a lot of detail, that means that R lives on its own on your computer in a separate directory, and RStudio provides a bunch of better functionality for things like writing multiple files at once, making editing easier, autofilling code, and displaying plots. You can learn more about RStudio here. With that out of the way, I am going to be sloppy in terminology and say/type “R” a lot of the times I mean “RStudio”. I will be very clear if the distinction actually matters. RStudio is going to make your life way easier, and when you try to learn Python you are going to be sad :( 1.2 The parts of RStudio The default layout of RStudio looks something like this (font sizes may vary): RStudio default layout, courtesy of Data Carpentry RStudio always has 4 “panes” with various functions, which are in tabs (just like a web browser). The key ones for right now to pay attention are: The Console tab is the portal to interact directly with R. The &gt; “prompt” is where you can type and execute commands (by hitting return). You can try this out right now by using it like a calculator - try 1 + 1 if you like! The Files tab shows the files in your working directory: like in the Windows Explorer or macOS Finder, files are displayed within folders. You can click on files to open them. The Help tab shows documentation for R functions and packages–it is useful for learning how to use specific functions. The Plots tab shows graphical output, and this is where the data visualizations we’ll learn to make will (generally) appear. The Environment tab shows the objects that exist in memory in your current R session. Without going into details, this is “what you’ve done” so far: data tables and variables you’ve created, etc. Finally, the Scripts pane shows individual tabs for each script and other RStudio file. Scripts (and other, more exotic file types like RMarkdown/.Rmd files) are documents that contain multiple R commands, like you’d type into the Console. However, unlike commands in the Console, these commands don’t disappear as soon as they’re run, and we can string them together to make workflows or even programs. This is where the real power of R will come from. You can change the layout of your Panes (and many other options) by going to the RStudio menu: Tools &gt; Global Options and select Pane Layout. You’ll notice that my layout for RStudio looks quite different from the default, but you can always orient yourself by seeing what tab or pane I am in–these are always the same. I prefer giving myself more space for writing R scripts and markdown files, so I have given that specific Pane more space while minimizing the History pane. While we’re in Global Options, please make the following selections: Under General, uncheck all the boxes to do with restoring projects and workspaces. We want to make sure our code runs the same time every time (i.e., that our methods are reproducible), and letting RStudio load these will make this impossible: Uncheck the options to restore various data and projects at startup. Make your life easier by setting up autocompletion for your code. Under the Code &gt; Completion options, select the checkboxes to allow using tab for autocompletions, and also allowing multiline autocompletions. This means that RStudio will suggest functions and data for you if you hit tab, which will make you have to do way less typing: Check the boxes for tab and multiline autocompletions. 1.2.1 The “working directory” and why you should care Before we move on to using R for real, we have one key general computing concept to tackle: the “working directory”. The working directory is the folder on your computer in which R will look for files and save files. When you need to tell R to read in data from a file or output a file, you will have to do so in relation to your working directory. Therefore, it is important that you know how to find your working directory and change it. The easiest (but not best) way to do this is to use the Files pane. If you hit the “gear” icon in the Files pane menu, you’ll see two commands to do with the working directory. You can Go To Working Directory to show you whatever R currently has set as the working directory. You can then navigate to any directory you want on your hard drive, and use the Set As Working Directory command to make that the working directory. A better way to do this is to use the R commands getwd() and setwd(). getwd() # will print the current working directory ## [1] &quot;C:/Users/lhamilton/Documents/sensometrics-r-tutorial-2024&quot; And we can manually change the working directory by using setwd(&quot;Enter/Your/Desired/Directory/Here&quot;) Notice that I am not running the second command, because it would cause an error! When we use R to navigate directories, I recommend always using the forward slash: /, even though on Windows systems the typical slash is the backslash: \\. R will properly interpret the / for you in the context of your operating system, and this is more consistent with most modern code environments. 1.3 Extending R with packages One of the key advantages of R is that its open-source nature means that you can extend it to do all sorts of things. For example, for much of this workshop we are going to use the tidyverse packages and the ca package. There are various ways to install new packages, but the easiest way is to use the Packages tab. This will show you all the packages you currently have installed as an alphabetical list. We install new packages using the install.packages() command. As part of the pre-work for the tutorial, you will have run the following commmands: # Install the tidyverse packages install.packages(&quot;tidyverse&quot;) # Install the ca package install.packages(&quot;ca&quot;) While these commands will download packages and install them in a directory on your hard drive where R can find them, they will not make them immediately usable in an R programming session. 1.3.1 Loading packages To actually use a package, you need to load it using the library(&lt;name of package&gt;) command. So, for example, to load the tidyverse package we will use the command library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.4 ✔ readr 2.1.4 ## ✔ forcats 1.0.0 ✔ stringr 1.5.1 ## ✔ ggplot2 3.4.2 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.2 ✔ tidyr 1.3.1 ## ✔ purrr 1.0.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors You need to use multiple library() commands to load multiple packages, e.g., library(tidyverse) library(ca) If you want to know what packages you have loaded, you can run the sessionInfo() function, which will tell you a bunch of stuff, including the “attached” packages: sessionInfo() ## R version 4.3.1 (2023-06-16 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 19045) ## ## Matrix products: default ## ## ## locale: ## [1] LC_COLLATE=English_United States.utf8 ## [2] LC_CTYPE=English_United States.utf8 ## [3] LC_MONETARY=English_United States.utf8 ## [4] LC_NUMERIC=C ## [5] LC_TIME=English_United States.utf8 ## ## time zone: America/New_York ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ca_0.71.1 lubridate_1.9.2 forcats_1.0.0 stringr_1.5.1 ## [5] dplyr_1.1.4 purrr_1.0.1 readr_2.1.4 tidyr_1.3.1 ## [9] tibble_3.2.1 ggplot2_3.4.2 tidyverse_2.0.0 ## ## loaded via a namespace (and not attached): ## [1] gtable_0.3.3 jsonlite_1.8.8 compiler_4.3.1 tidyselect_1.2.1 ## [5] jquerylib_0.1.4 scales_1.3.0 yaml_2.3.7 fastmap_1.1.1 ## [9] R6_2.5.1 generics_0.1.3 knitr_1.43 bookdown_0.34 ## [13] munsell_0.5.1 bslib_0.7.0 pillar_1.9.0 tzdb_0.4.0 ## [17] rlang_1.1.1 utf8_1.2.4 stringi_1.7.12 cachem_1.0.8 ## [21] xfun_0.39 sass_0.4.9 timechange_0.2.0 cli_3.6.1 ## [25] withr_3.0.0 magrittr_2.0.3 digest_0.6.33 grid_4.3.1 ## [29] rstudioapi_0.15.0 hms_1.1.3 lifecycle_1.0.4 vctrs_0.6.5 ## [33] evaluate_0.23 glue_1.6.2 fansi_1.0.6 colorspace_2.1-0 ## [37] rmarkdown_2.23 tools_4.3.1 pkgconfig_2.0.3 htmltools_0.5.8.1 Finally, you can also load (and unload) packages using the Packages tab, by clicking the checkbox next to the name of the package you want to load (or unload). Typically, we think it’s a good idea to put all of your library() function calls at the top of your script, so that you don’t try to call a function from a package that has been loaded “later” (further down) in your script and cause an error. 1.4 Making R do stuff We can make R act as a basic calculator: 2 + 3 ## [1] 5 4 / 124 ## [1] 0.03225806 Mostly, we will be using R for writing complex, functional programs, in which we assign variables and use those variables in functions: x &lt;- &quot;dog&quot; ifelse(x == &quot;cat&quot;, &quot;Definitely feline!&quot;, &quot;You&#39;ve got something else there!&quot;) ## [1] &quot;You&#39;ve got something else there!&quot; 1.5 Livecoding along We’ve now covered the Console tab and the Scripts pane. These are both areas in which you can write and execute code, but they work a little differently. The Console is the place to run code that is short and easy to type, or that you’re experimenting with. It will allow you to write a single line of code, and after you hit return, R will execute the command. This is great for “interactive programming”, but it isn’t so great for building up a complex workflow, or for following along with this workshop! This is why I have recommended that you create a new script to follow along with this workshop. You get a new script by going to File &gt; New File &gt; R Script. You can write multiple lines of code and then execute each one in any order (although keeping a logical sequence from top to bottom will help you keep track of what you’re doing). In an R script, everything is expected to be valid R code. You can&#39;t write this in an R script because it is plain text. This will cause an error. # If you want to write text or notes to yourself, use the &quot;#&quot; symbol at the start of # every line to &quot;comment&quot; out that line. You can also put &quot;#&quot; in the middle of # a line in order to add a comment - everything after will be ignored. 1 + 1 # this is valid R syntax print(&quot;hello world&quot;) # this is also valid R syntax To run code from your R script, put your cursor on the line you want to run and either hit the run button with the green arrow at the top left or (my preferred method) type cmd + return (on Mac) or ctrl + return (on PC). 1.6 Summary and next steps We’ve now run through briefly the “what” of the R/RStudio interface. Next, we’re going to dive into importing some sensory datasets and processing them for visualization. "],["importing-and-wrangling-data.html", "2 Importing and wrangling data 2.1 Motivation: exploring berry and cider CATA/liking data 2.2 Getting data into R 2.3 Wrangling (selecting, filtering, reshaping) data 2.4 Saving your data 2.5 Wrap up", " 2 Importing and wrangling data Now that everyone is on the same page for how we’re going to use R, we’re going to dive right into importing our data into R, exploring it, and–most importantly–visualizing it. In this part of the tutorial, we are going to focus on getting data into R and manipulating it. Personally, I prefer to see the reason for doing something, rather than being shown a bunch of building blocks and not seeing how they fit together. Therefore, we’re going to start off this section with a complete work flow for importing and visualizing some real results, and then work backward as we unpack how and why we’ve taken particular steps. 2.1 Motivation: exploring berry and cider CATA/liking data Before we begin, we need to make sure we’ve loaded the packages we’re going to use. # This package is actually a set of utility packages we will use a lot library(tidyverse) The plan here is to present “full” workflows for data import, wrangling, and visualization below so as to give a skeleton to work through. This is going to look like a lot of code at once, but I don’t use anything in these workflows that we will not be covering (in some way!) today. Hopefully, by the end of today’s workshop you will be able both to understand and dissect complex code and use it to build your own analyses and visualizations. 2.1.1 Berries Here we are going to import and process data from a study on berries. These data come from a large, central-location study on berries, the methodological details of which are published in Yeung et al. (2021). Very briefly, the data describe the attributes and liking scores reported by consumers for a variety of berries across multiple CLTs. A total of 969 participants (Subject Code) and 23 berries (Sample Name) were involved in these tests, with only one species of berry (blackberry, blueberry, raspberry, or strawberry) presented during each CLT. In the actual experimental design, subjects got multiple sample sets (so there are not 969 unique subjects), but here we will treat them as unique for ease of description. # Import the data raw_berry_data &lt;- read_csv(file = &quot;data/clt-berry-data.csv&quot;) %&gt;% select(where(~ !all(is.na(.)))) cleaned_berry_data &lt;- raw_berry_data %&gt;% # Get the relevant columns select(`Subject Code`, berry, sample, starts_with(&quot;cata_&quot;), contains(&quot;overall&quot;)) %&gt;% # Rescale the LAM and US scales to a 9-pt range mutate(lms_overall = (lms_overall + 100) * (8 / 200) + 1, us_overall = (us_overall + 0) * (8 / 15) + 1) %&gt;% # Switch the 3 overall liking columns into a single column pivot_longer(contains(&quot;overall&quot;), names_to = &quot;hedonic_scale&quot;, values_to = &quot;rating&quot;, values_drop_na = TRUE) %&gt;% # Let&#39;s make all the CATA variables into a single column to make life easier # (and get rid of those NAs) pivot_longer(starts_with(&quot;cata_&quot;), names_to = &quot;cata_variable&quot;, values_to = &quot;checked&quot;, names_transform = ~str_remove(., &quot;cata_&quot;), values_drop_na = TRUE) berry_penalty_analysis_data &lt;- cleaned_berry_data %&gt;% group_by(berry, cata_variable, checked) %&gt;% summarize(penalty_lift = mean(rating), count = n()) %&gt;% ungroup() # Make a plot of the overall penalty/lift for checked attributes p1_berry_penalty &lt;- berry_penalty_analysis_data %&gt;% select(-count) %&gt;% pivot_wider(names_from = checked, values_from = penalty_lift, names_prefix = &quot;checked_&quot;) %&gt;% group_by(berry, cata_variable) %&gt;% summarize(penalty_lift = checked_1 - checked_0) %&gt;% # We can tidy up our CATA labels separate(cata_variable, into = c(&quot;mode&quot;, &quot;variable&quot;), sep = &quot;_&quot;) %&gt;% # Fix a typo mutate(mode = str_replace(mode, &quot;appearane&quot;, &quot;appearance&quot;)) %&gt;% mutate(mode = case_when(mode == &quot;taste&quot; ~ &quot;(T)&quot;, mode == &quot;appearance&quot; ~ &quot;(A)&quot;)) %&gt;% unite(variable, mode, col = &quot;cata_variable&quot;, sep = &quot; &quot;) %&gt;% # We are using a function from tidytext that makes faceting the final figure # easier mutate(cata_variable = tidytext::reorder_within(x = cata_variable, by = penalty_lift, within = berry)) %&gt;% #And finally we plot! ggplot(mapping = aes(x = cata_variable, y = penalty_lift)) + geom_col(aes(fill = penalty_lift), color = &quot;white&quot;, show.legend = FALSE) + facet_wrap(~berry, scales = &quot;free&quot;, nrow = 1) + tidytext::scale_x_reordered() + coord_flip() + theme_classic() + scale_fill_gradient(low = &quot;tan&quot;, high = &quot;darkgreen&quot;) + labs(x = NULL, y = NULL, title = &quot;Penalty / Lift Analysis&quot;, subtitle = &quot;displays the mean difference (within berries) for when a CATA variable is checked\\nor un-checked&quot;) p1_berry_penalty 2.1.2 Cider Now, let’s get our cider data. These data come from a small consumer study on 3 commercial “hard” (alcoholic) ciders, served in two conditions (chilled or unchilled) to 48 consumers, who used a pre-defined CATA lexicon, rated overall liking, and evaluated cider “dryness” on a 4-pt, structured line scale. The full details of the study are published in Calvert et al. (2022). raw_cider_data &lt;- read_csv(&quot;data/CiderDryness_SensoryDATA.csv&quot;) cider_penalty_data &lt;- raw_cider_data %&gt;% pivot_longer(Fresh_Apples:Synthetic, names_to = &quot;cata_variable&quot;, values_to = &quot;checked&quot;) %&gt;% group_by(cata_variable, checked) %&gt;% summarize(rating = mean(Liking), count = n()) %&gt;% mutate(proportion = count / sum(count)) %&gt;% ungroup() # Define the &quot;important&quot; penalty/lift zones zones &lt;- tribble(~penalty_lift, ~xmin, ~xmax, ~ymin, ~ymax, &quot;penalty&quot;, 0.25, Inf, -Inf, -1, &quot;lift&quot;, 0.25, Inf, 1, Inf) # Let&#39;s make a plot where we take into account the frequency of checking as well # as the penalty p2_cider_penalty &lt;- cider_penalty_data %&gt;% select(-count, -proportion) %&gt;% pivot_wider(names_from = checked, values_from = rating) %&gt;% mutate(penalty = `1` - `0`) %&gt;% left_join(cider_penalty_data %&gt;% filter(checked == 1) %&gt;% select(cata_variable, proportion)) %&gt;% # And now we plot! ggplot(aes(x = proportion, y = penalty)) + geom_hline(yintercept = 0) + geom_rect(aes(xmin = xmin, ymin = ymin, xmax = xmax, ymax = ymax, fill = penalty_lift, color = penalty_lift), data = zones, inherit.aes = FALSE, linetype = 2) + geom_point() + ggrepel::geom_label_repel(aes(label = cata_variable), alpha = 2/3) + scale_fill_manual(&quot;penalty / lift zone:&quot;, values = alpha(c( &quot;darkgreen&quot;, &quot;tan&quot;), alpha = 1/4)) + scale_color_manual(NULL, values = c( &quot;darkgreen&quot;, &quot;tan&quot;), breaks = NULL) + theme_bw() + theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(), legend.position = &quot;top&quot;) + labs(x = &quot;Proportion of checks for CATA attribute&quot;, y = &quot;Change in average liking when CATA\\nattribute is checked&quot;, title = &quot;Penalty/Lift Analysis&quot;, subtitle = &quot;in which average change is plotted against check frequency&quot;) p2_cider_penalty 2.1.3 “Publication quality” What do we mean by “publication quality” visualizations? Neither of us are theorists of visualization–for that, we would recommend that you look at the excellent work from Claus Wilke and Kieran Healey. We will not be discussing (in any detail) ideas about which color palettes best communicate different types of data, what kinds of displays are most effective (box plots vs violin plots vs …), or whether pie charts are really so bad (mostly yes). Rather, we have noticed that most R packages for data analysis provide visualizations as part of their output, and many sensory scientists are using these default outputs in publications. This is annoying because often these visualizations are meant to be part of the data exploration/analysis process: they are not polished or they don’t display the data to its best advantage (whatever that is for the particular case). In this workshop, we want to help you develop the competency to alter or re-make these visualizations for yourself so that you can produce visualizations that are relevant to your application, that are attractive and easy to read. As an example, the FactoMineR package has excellent default visualizations for exploring and understanding the basic outputs of many common multivariate analyses used by sensory scientists. We can take a look at our cider CATA data visualized as a symmetric CA “biplot” without much effort: ca_cider &lt;- raw_cider_data %&gt;% select(Sample_Name, Temperature, Fresh_Apples:Synthetic) %&gt;% unite(Sample_Name, Temperature, col = &quot;sample&quot;, sep = &quot; &quot;) %&gt;% group_by(sample) %&gt;% summarize(across(where(is.numeric), ~sum(.))) %&gt;% column_to_rownames(&quot;sample&quot;) %&gt;% FactoMineR::CA(graph = FALSE) p3_cider_factominer &lt;- plot(ca_cider) p3_cider_factominer But there might be things about this we want to change! It would be very helpful to know, for example, that this is a ggplot2 object that can be altered by a basic handful of standardized syntax. For example: p3_cider_factominer + theme_dark() + labs(caption = &quot;Now we can say some more things!&quot;, subtitle = &quot;of 6 ciders tasted by 48 subjects&quot;) Like I said, we’re not here to tell you how your plots should look… The motivating point, here, is to be able to make visualizations that accomplish what you want them to, rather than being at the mercy of packages that have certain defaults built in. 2.2 Getting data into R Before we’re able to analyze anything, we need to get data into R. In the workshop archive you downloaded, the data/ directory has files called clt-berry-data.csv and CiderDryness_SensoryDATA.csv. These are the files that hold the raw data. 2.2.1 Where the data live To get these data into R, we need to briefly talk about working directories because this is how R “sees” your computer. It will look first in the working directory, and then you will have to tell it where the file is relative to that directory. If you have been following along and opened up the .Rproj file in the downloaded archive, your working directory should be the archive’s top level, which will mean that we only need to point R towards the data/ folder and then the clt-berry-data.csv file. We can check the working directory with the getwd() function. getwd() ## [1] &quot;C:/Users/lhamilton/Documents/sensometrics-r-tutorial-2024&quot; Therefore, relative to the working directory, the file path to this data is data/clt-berry-data.csv. Please note that this is the UNIX convention for file paths: in Windows, the backslash \\ is used to separate directories. Happily, RStudio will translate between the two conventions, so you can just follow along with the macOS/UNIX convention (/) in this workshop. 2.2.2 Getting different kinds of files into R The first step is to notice this is a .csv file, which stands for comma-separated value. This means our data, in raw format, looks something like this: # Comma-separated data (regarding Jake&#39;s cats) cat_acquisition_order,name,weight,age\\n 1,Nick,9,17\\n 2,Margot,7,16\\n 3,Little Guy,13,4\\n Each line represents a row of data, and each field is separated by a comma (,). We can read this kind of data into R by using the read_csv() function (this is a nicer version of the default read.csv() function, and we get access to it by loading tidyverse with library(tidyverse)). read_csv(file = &quot;data/clt-berry-data.csv&quot;) ## # A tibble: 7,507 × 92 ## `Subject Code` `Participant Name` Gender Age `Start Time (UTC)` ## &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;chr&gt; ## 1 1001 1001 NA NA 6/13/2019 21:05 ## 2 1001 1001 NA NA 6/13/2019 20:55 ## 3 1001 1001 NA NA 6/13/2019 20:49 ## 4 1001 1001 NA NA 6/13/2019 20:45 ## 5 1001 1001 NA NA 6/13/2019 21:00 ## 6 1001 1001 NA NA 6/13/2019 21:10 ## 7 1002 1002 NA NA 6/13/2019 20:08 ## 8 1002 1002 NA NA 6/13/2019 19:57 ## 9 1002 1002 NA NA 6/13/2019 20:13 ## 10 1002 1002 NA NA 6/13/2019 20:03 ## # ℹ 7,497 more rows ## # ℹ 87 more variables: `End Time (UTC)` &lt;chr&gt;, `Serving Position` &lt;dbl&gt;, ## # `Sample Identifier` &lt;dbl&gt;, `Sample Name` &lt;chr&gt;, `9pt_appearance` &lt;dbl&gt;, ## # pre_expectation &lt;dbl&gt;, jar_color &lt;dbl&gt;, jar_gloss &lt;dbl&gt;, jar_size &lt;dbl&gt;, ## # cata_appearance_unevencolor &lt;dbl&gt;, cata_appearance_misshapen &lt;dbl&gt;, ## # cata_appearance_creased &lt;dbl&gt;, cata_appearance_seedy &lt;dbl&gt;, ## # cata_appearance_bruised &lt;dbl&gt;, cata_appearance_notfresh &lt;dbl&gt;, … read_csv(file = &quot;data/CiderDryness_SensoryDATA.csv&quot;) ## # A tibble: 288 × 27 ## Sample_Name Temperature Panelist_Code MerlynScale_Ranking Fresh_Apples ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1911 Est. Chilled 001 2.3 1 ## 2 Buskey Chilled 001 3.5 1 ## 3 Eden Chilled 001 2.8 0 ## 4 1911 Est. RT 001 4.2 0 ## 5 Buskey RT 001 2 0 ## 6 Eden RT 001 4 0 ## 7 1911 Est. Chilled 002 3 1 ## 8 Buskey Chilled 002 3.3 0 ## 9 Eden Chilled 002 3.5 1 ## 10 1911 Est. RT 002 4.5 0 ## # ℹ 278 more rows ## # ℹ 22 more variables: Fermented &lt;dbl&gt;, Herbal &lt;dbl&gt;, Dry &lt;dbl&gt;, Spice &lt;dbl&gt;, ## # Fruity &lt;dbl&gt;, Smooth &lt;dbl&gt;, Alcohol &lt;dbl&gt;, Light &lt;dbl&gt;, Sweet &lt;dbl&gt;, ## # Woody &lt;dbl&gt;, Berries &lt;dbl&gt;, Sour &lt;dbl&gt;, Funky &lt;dbl&gt;, FullBodied &lt;dbl&gt;, ## # Metallic &lt;dbl&gt;, Floral &lt;dbl&gt;, Candy &lt;dbl&gt;, Bitter &lt;dbl&gt;, Vomit &lt;dbl&gt;, ## # Earthy &lt;dbl&gt;, Synthetic &lt;dbl&gt;, Liking &lt;dbl&gt; Remember that we need to store objects in the Environment if we want to access and modify them. Therefore, we need to remember to store these somewhere. raw_berry_data &lt;- read_csv(file = &quot;data/clt-berry-data.csv&quot;) raw_cider_data &lt;- read_csv(file = &quot;data/CiderDryness_SensoryDATA.csv&quot;) As a note, in many countries the separator (delimiter) will be the semi-colon (;), since the comma is used as the decimal marker. To read files formatted this way, you can use the read_csv2() function. If you encounter tab-separated values files (.tsv) you can use the read_tsv() function. If you have more non-standard delimiters, you can use the read_delim() function, which will allow you to specify your own delimiter characters. Excel stores data by default in the .xlsx format, which can be read by installing and using the readxl package (or saving Excel data as .csv). You can also read many other formats of tabular data using the rio package (“read input/output”), which can be installed from CRAN (using, as you have learned, install.packages(\"rio\")). The read_csv() function creates a type of object in R called a tibble, which is a special type of data.frame. These are rectangular “spreadsheet-like” objects like you would encounter in Excel or manipulate in JMP or SPSS. We can learn more about the objects we just created by either examining them in the Environment tab or, preferably, using the glimpse() function to get a look at what we have (note that glimpse() comes from tidyverse; if you don’t load it by running library(tidyverse) earlier in your session you will get an error). glimpse(raw_berry_data) ## Rows: 7,507 ## Columns: 92 ## $ `Subject Code` &lt;dbl&gt; 1001, 1001, 1001, 1001, 1001, 1001, 1002, … ## $ `Participant Name` &lt;dbl&gt; 1001, 1001, 1001, 1001, 1001, 1001, 1002, … ## $ Gender &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Age &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `Start Time (UTC)` &lt;chr&gt; &quot;6/13/2019 21:05&quot;, &quot;6/13/2019 20:55&quot;, &quot;6/1… ## $ `End Time (UTC)` &lt;chr&gt; &quot;6/13/2019 21:09&quot;, &quot;6/13/2019 20:59&quot;, &quot;6/1… ## $ `Serving Position` &lt;dbl&gt; 5, 3, 2, 1, 4, 6, 3, 1, 4, 2, 6, 5, 2, 4, … ## $ `Sample Identifier` &lt;dbl&gt; 1426, 3167, 4624, 5068, 7195, 9161, 1426, … ## $ `Sample Name` &lt;chr&gt; &quot;raspberry 6&quot;, &quot;raspberry 5&quot;, &quot;raspberry 2… ## $ `9pt_appearance` &lt;dbl&gt; 4, 8, 4, 7, 7, 7, 6, 8, 8, 7, 9, 8, 5, 5, … ## $ pre_expectation &lt;dbl&gt; 2, 4, 2, 4, 3, 4, 2, 3, 5, 3, 4, 5, 3, 3, … ## $ jar_color &lt;dbl&gt; 2, 3, 2, 2, 4, 4, 2, 3, 3, 2, 3, 4, 3, 3, … ## $ jar_gloss &lt;dbl&gt; 4, 3, 2, 3, 3, 3, 4, 3, 4, 4, 2, 4, 3, 3, … ## $ jar_size &lt;dbl&gt; 2, 3, 3, 4, 3, 3, 4, 3, 5, 3, 3, 4, 3, 3, … ## $ cata_appearance_unevencolor &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, … ## $ cata_appearance_misshapen &lt;dbl&gt; 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, … ## $ cata_appearance_creased &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, … ## $ cata_appearance_seedy &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ cata_appearance_bruised &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, … ## $ cata_appearance_notfresh &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, … ## $ cata_appearance_fresh &lt;dbl&gt; 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, … ## $ cata_appearance_goodshape &lt;dbl&gt; 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, … ## $ cata_appearance_goodquality &lt;dbl&gt; 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, … ## $ cata_appearance_none &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ `9pt_overall` &lt;dbl&gt; 4, 9, 3, 7, 4, 4, 4, 7, 7, 9, 7, 2, 8, 7, … ## $ verbal_likes &lt;chr&gt; &quot;Out of the two, there was one that had a … ## $ verbal_dislikes &lt;chr&gt; &quot;There were different flavors coming from … ## $ `9pt_taste` &lt;dbl&gt; 4, 9, 3, 6, 3, 3, 4, 4, 6, 9, 6, 2, 8, 7, … ## $ grid_sweetness &lt;dbl&gt; 3, 6, 3, 6, 2, 3, 3, 2, 2, 6, 4, 1, 6, 4, … ## $ grid_tartness &lt;dbl&gt; 6, 5, 5, 3, 5, 6, 5, 5, 5, 2, 2, 7, 4, 5, … ## $ grid_raspberryflavor &lt;dbl&gt; 4, 7, 2, 6, 2, 3, 2, 6, 2, 7, 2, 2, 6, 5, … ## $ jar_sweetness &lt;dbl&gt; 2, 3, 2, 3, 2, 1, 1, 1, 1, 3, 2, 1, 3, 3, … ## $ jar_tartness &lt;dbl&gt; 4, 3, 3, 3, 4, 5, 4, 4, 4, 3, 4, 5, 3, 3, … ## $ cata_taste_floral &lt;dbl&gt; 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, … ## $ cata_taste_berry &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, … ## $ cata_taste_green &lt;dbl&gt; 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, … ## $ cata_taste_grassy &lt;dbl&gt; 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, … ## $ cata_taste_fermented &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ cata_taste_tropical &lt;dbl&gt; 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, … ## $ cata_taste_fruity &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, … ## $ cata_taste_citrus &lt;dbl&gt; 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, … ## $ cata_taste_earthy &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, … ## $ cata_taste_candy &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, … ## $ cata_taste_none &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ `9pt_texture` &lt;dbl&gt; 6, 8, 2, 8, 5, 6, 6, 9, 8, 7, 7, 7, 8, 7, … ## $ grid_seediness &lt;dbl&gt; 3, 5, 6, 3, 5, 5, 6, 4, 6, 5, 6, 5, 4, 4, … ## $ grid_firmness &lt;dbl&gt; 5, 5, 5, 2, 6, 5, 5, 6, 5, 3, 5, 5, 4, 5, … ## $ grid_juiciness &lt;dbl&gt; 2, 5, 2, 2, 2, 4, 2, 4, 2, 3, 3, 2, 6, 5, … ## $ jar_firmness &lt;dbl&gt; 3, 3, 4, 2, 4, 3, 3, 3, 3, 2, 3, 3, 3, 3, … ## $ jar_juciness &lt;dbl&gt; 2, 3, 1, 2, 2, 2, 1, 2, 1, 3, 2, 1, 3, 3, … ## $ post_expectation &lt;dbl&gt; 1, 5, 2, 4, 2, 2, 2, 2, 2, 5, 2, 1, 4, 3, … ## $ price &lt;dbl&gt; 1.99, 4.99, 2.99, 4.99, 2.99, 3.99, 3.99, … ## $ product_tier &lt;dbl&gt; 1, 3, 2, 3, 1, 2, 2, 2, 1, 3, 2, 1, 2, 2, … ## $ purchase_intent &lt;dbl&gt; 1, 5, 2, 4, 2, 2, 3, 4, 2, 5, 3, 1, 5, 5, … ## $ subject &lt;dbl&gt; 1031946, 1031946, 1031946, 1031946, 103194… ## $ test_day &lt;chr&gt; &quot;Raspberry Day 1&quot;, &quot;Raspberry Day 1&quot;, &quot;Ras… ## $ us_appearance &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ us_overall &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ us_taste &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ us_texture &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ lms_appearance &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ lms_overall &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ lms_taste &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ lms_texture &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_appearane_bruised &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_appearance_goodshapre &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_appearance_goodcolor &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ grid_blackberryflavor &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_cinnamon &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_lemon &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_clove &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_minty &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_grape &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ grid_crispness &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ jar_crispness &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ jar_juiciness &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_appearane_creased &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ grid_blueberryflavor &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_piney &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_peachy &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `9pt_aroma` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ grid_strawberryflavor &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_caramel &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_grapey &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_melon &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_cherry &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ grid_crunchiness &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ jar_crunch &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ us_aroma &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ lms_aroma &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ berry &lt;chr&gt; &quot;raspberry&quot;, &quot;raspberry&quot;, &quot;raspberry&quot;, &quot;ra… ## $ sample &lt;dbl&gt; 6, 5, 2, 3, 4, 1, 6, 5, 2, 3, 4, 1, 6, 5, … glimpse(raw_cider_data) ## Rows: 288 ## Columns: 27 ## $ Sample_Name &lt;chr&gt; &quot;1911 Est.&quot;, &quot;Buskey&quot;, &quot;Eden&quot;, &quot;1911 Est.&quot;, &quot;Buske… ## $ Temperature &lt;chr&gt; &quot;Chilled&quot;, &quot;Chilled&quot;, &quot;Chilled&quot;, &quot;RT&quot;, &quot;RT&quot;, &quot;RT&quot;,… ## $ Panelist_Code &lt;chr&gt; &quot;001&quot;, &quot;001&quot;, &quot;001&quot;, &quot;001&quot;, &quot;001&quot;, &quot;001&quot;, &quot;002&quot;, &quot;… ## $ MerlynScale_Ranking &lt;dbl&gt; 2.3, 3.5, 2.8, 4.2, 2.0, 4.0, 3.0, 3.3, 3.5, 4.5, … ## $ Fresh_Apples &lt;dbl&gt; 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,… ## $ Fermented &lt;dbl&gt; 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,… ## $ Herbal &lt;dbl&gt; 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,… ## $ Dry &lt;dbl&gt; 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ Spice &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ Fruity &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,… ## $ Smooth &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ Alcohol &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ Light &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,… ## $ Sweet &lt;dbl&gt; 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,… ## $ Woody &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ Berries &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ Sour &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,… ## $ Funky &lt;dbl&gt; 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,… ## $ FullBodied &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,… ## $ Metallic &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,… ## $ Floral &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,… ## $ Candy &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,… ## $ Bitter &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ Vomit &lt;dbl&gt; 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ Earthy &lt;dbl&gt; 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ Synthetic &lt;dbl&gt; 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,… ## $ Liking &lt;dbl&gt; 6, 7, 4, 2, 7, 5, 8, 6, 7, 3, 4, 4, 7, 6, 5, 6, 4,… This tells us how many rows we have, what the names of our columns (variables) are, what kind of column they are (numeric, character, logical, etc), and a preview of the first few entres in each column. 2.3 Wrangling (selecting, filtering, reshaping) data Our students often tell us that the hardest part of data analysis and visualization is getting data into the tool you want to use (here R) and into the right “shape” for the relevant analysis. We tend to agree: a common saying in data science is that about 90% of the effort in an analysis workflow is in getting data wrangled into the right format and shape, and 10% is actual analysis. In a point and click program like SPSS or XLSTAT we don’t think about this as much because the activity of reshaping the data–making it longer or wider as required, finding and cleaning missing values, selecting columns or rows, etc–is often temporally and programmatically separated from the “actual” analysis. In R, this can feel a bit different because we are using the same interface to manipulate our data and to analyze it. Sometimes we’ll want to jump back out to a spreadsheet program like Excel or even the command line (the “shell” like bash or zsh) to make some changes. But in general the tools for manipulating data in R are both more powerful and more easily used than doing these activities by hand, and you will make yourself a much more effective analyst by mastering these basic tools. Here, we are going to emphasize the set of tools from the tidyverse, which are extensively documented in Hadley Wickham and Garrett Grolemund’s book R for Data Science. If you want to learn more, start there! The tidyverse is associated with this hexagonal iconography. If you’re at all familiar with R, you will have learned about subsetting R objects like lists and data frames using operators like [ or [[ and logical comparisons like x &lt; 10. If you are used to code conventions, this is a great system! However, for people who are less familiar with coding, these are often difficult to parse and to remember. So in this workshop we’re going to assume you’ve been exposed to this information, and we’re not going to use or focus on it very much; instead, we’re going to look at the tools within the tidyverse that accomplish the same things in–we think!–a much easier to parse and remember fashion. 2.3.1 The “pipe” for multiple steps in a workflow: %&gt;% While I am not going to go over much of the base R syntax, I want to talk about one particular tool that is becoming standard in modern R coding: the pipe, which is written in tidyverse as %&gt;%. This garbage-looking set of symbols is actually your best friend, you just don’t know it yet. I use this tool constantly in my R programming. OK, enough background, what the heck is a pipe? The term “pipe” comes from what it does: like a pipe, %&gt;% lets whatever is on its left side flow through to the right hand side. It is easiest to read %&gt;% as “AND THEN”. raw_berry_data %&gt;% # Start with the berry_data filter(berry == &quot;blackberry&quot;) %&gt;% # AND THEN filter to blackberries select(`Sample Name`, # AND THEN select sample name, overall liking... contains(&quot;_overall&quot;), contains(&quot;cata_&quot;)) ## # A tibble: 1,495 × 40 ## `Sample Name` `9pt_overall` us_overall lms_overall cata_appearance_unevenco…¹ ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Blackberry 4 2 NA NA 0 ## 2 Blackberry 2 5 NA NA 0 ## 3 Blackberry 1 8 NA NA 0 ## 4 Blackberry 3 6 NA NA 0 ## 5 Blackberry 5 8 NA NA 0 ## 6 Blackberry 4 6 NA NA 0 ## 7 Blackberry 2 1 NA NA 0 ## 8 Blackberry 1 8 NA NA 0 ## 9 Blackberry 3 8 NA NA 0 ## 10 Blackberry 5 8 NA NA 0 ## # ℹ 1,485 more rows ## # ℹ abbreviated name: ¹​cata_appearance_unevencolor ## # ℹ 35 more variables: cata_appearance_misshapen &lt;dbl&gt;, ## # cata_appearance_creased &lt;dbl&gt;, cata_appearance_seedy &lt;dbl&gt;, ## # cata_appearance_bruised &lt;dbl&gt;, cata_appearance_notfresh &lt;dbl&gt;, ## # cata_appearance_fresh &lt;dbl&gt;, cata_appearance_goodshape &lt;dbl&gt;, ## # cata_appearance_goodquality &lt;dbl&gt;, cata_appearance_none &lt;dbl&gt;, … Typing %&gt;% is no fun. But, happily, RStudio builds in a shortcut for you: macOS is cmd + shift + M, Windows is ctrl + shift + M. Please note that since R 4.1, a native pipe has been implemented (you don’t need to load tidyverse for it to work), which is written as |&gt;. If you are new to using pipes, you can pretty safely use either one that you prefer, and you can configure the keyboard shortcuts above to use either the native or tidyverse pipe. The default depends on your version of Rstudio. If you want to learn details, this article is helpful. TL;DR: The pipe lets us quickly write functional workflows without saving a lot of intermediate steps. We’re going to use it a lot in the following examples, and I’ll call it out the first few times so that you can get the hang of it. 2.3.2 Subsetting your data The first thing you’ll notice about our raw_berry_data in particular is that it is full of information we don’t need! A common situation in R is wanting to select some rows and some columns of our data–this is called “subsetting” our data. But this is less easy than it might be for the beginner in R. Happily, the tidverse methods are much easier to read (and modeled after syntax from SQL, which may be helpful for some users). 2.3.2.1 Selecting certain columns: select() The first thing we did in our code to wrangle our raw_berry_data into something useful was to determine that a number of columns were not necessary. We really only want the subject ID, the sample ID columns, and the CATA and the liking data. The rest of the data is either metadata (test date, etc) or other kinds of data that are not relevant to our analysis. We want to get rid of these. The tidyverse::select() function (we write [package]::[function] to explicitly describe where a function comes from) lets us select columns in a rectangular data frame (like .csv and other spreadsheets) by name, position, or logical criteria. The subject ID is stored in a column called Subject Code, and the berry information is stored in two columns: berry and sample, indicating what kind of berry and what sample # it is. raw_berry_data %&gt;% # We start with our raw_berry_data frame select(`Subject Code`, # AND THEN we select these 3 columns berry, sample) %&gt;% # AND THEN we use glimpse() to get a quick summary glimpse() ## Rows: 7,507 ## Columns: 3 ## $ `Subject Code` &lt;dbl&gt; 1001, 1001, 1001, 1001, 1001, 1001, 1002, 1002, 1002, 1… ## $ berry &lt;chr&gt; &quot;raspberry&quot;, &quot;raspberry&quot;, &quot;raspberry&quot;, &quot;raspberry&quot;, &quot;ra… ## $ sample &lt;dbl&gt; 6, 5, 2, 3, 4, 1, 6, 5, 2, 3, 4, 1, 6, 5, 2, 3, 4, 1, 6… Now we only have these 3 columns! An aside: Note the way that Subject Code is written: as `Subject Code`. This is because R will see some characters, including (but not limited to) white space (), leading numbers (starting with 1-9), and special characters (like , or :), as indications that the variable name has ended. We can refer to these strange column names by using the back-tick operator ` to escape the normal naming conventions. This happens often when, as we did here, we import data that wasn’t made in R, like many .csv files. It is a pain to type back-ticks, but the tab-completion behavior we set up makes this easier. To return to selection, we also want overall liking data and we want CATA variables. There are a lot of these, and typing them out individually in select() would be a pain. Luckily, there are a set of special functions for use within select() (and other tidyverse functions) that let us use logical operators to select ranges of columns/variables You can learn about them using the ?select command to get the help file. berry_columns &lt;- raw_berry_data %&gt;% select(`Subject Code`, berry, sample, starts_with(&quot;cata&quot;), # select columns whose names start with &quot;cata&quot; contains(&quot;overall&quot;)) # select columns whose names contain &quot;overall&quot; berry_columns %&gt;% glimpse() ## Rows: 7,507 ## Columns: 42 ## $ `Subject Code` &lt;dbl&gt; 1001, 1001, 1001, 1001, 1001, 1001, 1002, … ## $ berry &lt;chr&gt; &quot;raspberry&quot;, &quot;raspberry&quot;, &quot;raspberry&quot;, &quot;ra… ## $ sample &lt;dbl&gt; 6, 5, 2, 3, 4, 1, 6, 5, 2, 3, 4, 1, 6, 5, … ## $ cata_appearance_unevencolor &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, … ## $ cata_appearance_misshapen &lt;dbl&gt; 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, … ## $ cata_appearance_creased &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, … ## $ cata_appearance_seedy &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ cata_appearance_bruised &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, … ## $ cata_appearance_notfresh &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, … ## $ cata_appearance_fresh &lt;dbl&gt; 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, … ## $ cata_appearance_goodshape &lt;dbl&gt; 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, … ## $ cata_appearance_goodquality &lt;dbl&gt; 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, … ## $ cata_appearance_none &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ cata_taste_floral &lt;dbl&gt; 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, … ## $ cata_taste_berry &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, … ## $ cata_taste_green &lt;dbl&gt; 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, … ## $ cata_taste_grassy &lt;dbl&gt; 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, … ## $ cata_taste_fermented &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ cata_taste_tropical &lt;dbl&gt; 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, … ## $ cata_taste_fruity &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, … ## $ cata_taste_citrus &lt;dbl&gt; 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, … ## $ cata_taste_earthy &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, … ## $ cata_taste_candy &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, … ## $ cata_taste_none &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ cata_appearane_bruised &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_appearance_goodshapre &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_appearance_goodcolor &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_cinnamon &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_lemon &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_clove &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_minty &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_grape &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_appearane_creased &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_piney &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_peachy &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_caramel &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_grapey &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_melon &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ cata_taste_cherry &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `9pt_overall` &lt;dbl&gt; 4, 9, 3, 7, 4, 4, 4, 7, 7, 9, 7, 2, 8, 7, … ## $ us_overall &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ lms_overall &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… Because I am intimately familiar with these data, I know that all of the CATA variables were stored in columns starting with \"cata\", and that ratings for overall acceptability were stored in columns that had \"overall\" somewhere in their name. Unlike in our original workflow, we have created an intermediate data frame called berry_columns to save us from repeating steps. But, as above in the original workflow, there is no reason we need to do this. In our workflow above, note that our cider data came to us pretty clean; we are not using select() anywhere to discard columns. 2.3.2.2 Filtering certain rows: filter() Frequently we only want to select some of our observations, which are typically stored in the rows in our rectangular data frames. select() won’t help us here, but its row-wise cousin, filter(), lets us filter down to only rows that meet some logical criteria. While you will notice that we do not use filter() on either the cider or the berry data above–we want to retain all of our observations in this case–it is easy to imagine situations in which we might want to only inspect a subset of our data. For example, in the berry data, perhaps we want to separate out our observations on raspberries from all of our other data. raw_berry_data %&gt;% distinct(berry) # distinct() gives all unique value combinations ## # A tibble: 4 × 1 ## berry ## &lt;chr&gt; ## 1 raspberry ## 2 blackberry ## 3 blueberry ## 4 strawberry # of the variables it is provided raw_berry_data %&gt;% filter(berry == &quot;raspberry&quot;) %&gt;% # we filter to only rows where the berry variable distinct(berry) # is equal to &quot;raspberry&quot; ## # A tibble: 1 × 1 ## berry ## &lt;chr&gt; ## 1 raspberry We can use filter() to get rows according to more complex criteria than the basic comparison operators in R (e.g., ==, !=, &gt;, &lt;, etc). I want to highlight two basic functions that are extremely useful here. First, the %in% operator will search for whatever is on the left-hand side within the vector provided right-hand side. This is especially useful when we don’t want to build a complicated Boolean search from those comparisons (using &amp;, |, etc). If we want to get both raspberries and blackberries, we can write: raw_berry_data %&gt;% filter(berry %in% c(&quot;raspberry&quot;, &quot;blackberry&quot;)) %&gt;% distinct(berry) ## # A tibble: 2 × 1 ## berry ## &lt;chr&gt; ## 1 raspberry ## 2 blackberry Second, since frequently we are using filter() to get rows that meet some criteria stored in categorical variables, the str_detect() function from stringr (a package within the tidyverse) is extremely useful, along with its cousins str_starts() and str_ends(). Let’s say we want to get the second test day for each berry. We can accomplish this by searching for “Day 2” in the text of the test_day variable. raw_berry_data %&gt;% distinct(test_day) ## # A tibble: 12 × 1 ## test_day ## &lt;chr&gt; ## 1 Raspberry Day 1 ## 2 Raspberry Day 2 ## 3 Raspberry Day 3 ## 4 Blackberry Day 1 ## 5 Blackberry Day 2 ## 6 Blackberry Day 3 ## 7 Blueberry Day 1 ## 8 Blueberry Day 2 ## 9 Blueberry Day 3 ## 10 Strawberry Day 1 ## 11 Strawberry Day 2 ## 12 Strawberry Day 3 raw_berry_data %&gt;% filter(str_detect(test_day, &quot;Day 2&quot;)) %&gt;% distinct(test_day) ## # A tibble: 4 × 1 ## test_day ## &lt;chr&gt; ## 1 Raspberry Day 2 ## 2 Blackberry Day 2 ## 3 Blueberry Day 2 ## 4 Strawberry Day 2 The combination of filter() and select() goes a long way to helping us wrangle our data into the right shape for our analyses. 2.3.3 Reshaping your data At this point, we’ve gotten data into R and applied some tools to select and filter only relevant variables and observations. However, we often find that our raw data needs to be actively transformed for analysis. We might find that we need to do simple operations like calculate new quantities based on our raw measurements, convert units, or create new indicator variables. All of these operations require us to look at existing variables and create new variables based on those existing variables/columns. We also might notice that we are storing our data in a format that doesn’t work for us. You might be familiar with the idea of pivot tables, especially from Excel. We often find that our data is in “wide” format when we need it to be “long”, or vice-versa. While this seems different from creating new variables, pivoting operations also look at the structure of data (how cells are created at the intersection of rows and columns) to create new rows or new columns. 2.3.3.1 Creating new columns: mutate() Let’s start with the simpler operation: creating new columns (variables) based on existing ones. We do this above in our workflow mutate(). Often, we want to create a new column temporarily, or to combine several existing columns. We can do this using the mutate() function. Let’s (for the moment) only consider the 9-pt hedonic scale, and create a variable that tells us whether the rating is higher than some cutoff (say 6/9, a common cutoff). berry_columns %&gt;% select(berry, sample, `9pt_overall`) %&gt;% # we select these for easy printing mutate(good = `9pt_overall` &gt; 6) ## # A tibble: 7,507 × 4 ## berry sample `9pt_overall` good ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; ## 1 raspberry 6 4 FALSE ## 2 raspberry 5 9 TRUE ## 3 raspberry 2 3 FALSE ## 4 raspberry 3 7 TRUE ## 5 raspberry 4 4 FALSE ## 6 raspberry 1 4 FALSE ## 7 raspberry 6 4 FALSE ## 8 raspberry 5 7 TRUE ## 9 raspberry 2 7 TRUE ## 10 raspberry 3 9 TRUE ## # ℹ 7,497 more rows Note the syntax above: in mutate(), we put the name of the variable we want to create (or change) on the left hand side of an assignment = operator, and then on the right-hand side we describe (in R code) how to define the new variable. Frequently, we want to update existing variables. We can do this by providing an existing column name on the left-hand side. In our berry workflow, we can observe that we have 3 (!) different columns measuring overall liking: 9pt_overall, lms_overall, and us_overall. Part of the original experiment was to compare the performance of 3 different hedonic scales (the 9-pt hedonic scale, the Labeled Affective Magnitude scale (mislabeled here as LMS), and an unstructured line scale). We found that these scales didn’t make a huge difference, so now we’d like to combine our data to improve our overall power. But this is a problem: the 9-pt scale has a range of \\([1,9]\\) LAM has a range of \\([-100,100]\\), and the unstructured line scale has a range of \\([0,15]\\). We need to rescale the data to a consistent metric. berry_columns %&gt;% mutate(lms_overall = (lms_overall + 100) * (8 / 200) + 1, us_overall = (us_overall + 0) * (8 / 15) + 1) %&gt;% select(`9pt_overall`, lms_overall, us_overall) %&gt;% summary() ## 9pt_overall lms_overall us_overall ## Min. :1.000 Min. :1.00 Min. :1.000 ## 1st Qu.:4.000 1st Qu.:4.64 1st Qu.:4.200 ## Median :6.000 Median :6.04 Median :5.800 ## Mean :5.679 Mean :5.81 Mean :5.529 ## 3rd Qu.:7.000 3rd Qu.:7.24 3rd Qu.:6.867 ## Max. :9.000 Max. :9.00 Max. :9.000 ## NA&#39;s :5062 NA&#39;s :5005 NA&#39;s :4947 mutate() is a very easy way to edit your data mid-pipe. So we might want to do some calculations, create a temporary variable using mutate(), and then continue our pipe. Unless we use &lt;- to store our mutate()’d data, the results will be only temporary. # Our changes from mutate() were not saved berry_columns %&gt;% select(`9pt_overall`, lms_overall, us_overall) %&gt;% summary() ## 9pt_overall lms_overall us_overall ## Min. :1.000 Min. :-100.00 Min. : 0.000 ## 1st Qu.:4.000 1st Qu.: -9.00 1st Qu.: 6.000 ## Median :6.000 Median : 26.00 Median : 9.000 ## Mean :5.679 Mean : 20.25 Mean : 8.491 ## 3rd Qu.:7.000 3rd Qu.: 56.00 3rd Qu.:11.000 ## Max. :9.000 Max. : 100.00 Max. :15.000 ## NA&#39;s :5062 NA&#39;s :5005 NA&#39;s :4947 berry_columns &lt;- berry_columns %&gt;% mutate(lms_overall = (lms_overall + 100) * (8 / 200) + 1, us_overall = (us_overall + 0) * (8 / 15) + 1) # And now they are berry_columns %&gt;% select(`9pt_overall`, lms_overall, us_overall) %&gt;% summary() ## 9pt_overall lms_overall us_overall ## Min. :1.000 Min. :1.00 Min. :1.000 ## 1st Qu.:4.000 1st Qu.:4.64 1st Qu.:4.200 ## Median :6.000 Median :6.04 Median :5.800 ## Mean :5.679 Mean :5.81 Mean :5.529 ## 3rd Qu.:7.000 3rd Qu.:7.24 3rd Qu.:6.867 ## Max. :9.000 Max. :9.00 Max. :9.000 ## NA&#39;s :5062 NA&#39;s :5005 NA&#39;s :4947 We have overwitten our original variables with rescaled versions of the LAM and unstructured scales. Now our values are commensurate. NB: Sometimes we want to simultaneously select() and mutate() columns; the transmute() function is a simple wrapper for both of these operations combined and is quite useful for longer and more complex workflows. The .keep argument of mutate() can also be used to keep a subset of columns, rather than the whole tibble. 2.3.3.2 Pivoting: pivot_longer()/pivot_wider() A key concept motivating the tidyverse is the idea of “tidy” data, which is typically also tied to the ability to move between “long” and “wide” data. Typically, tidy data means data that is “long”, although I don’t know if I am convinced that it is an exact 1-to-1 map. Frequently, sensory data is recorded “wide”, with experimental units in rows and all of the measured or observed variables on those experimental units in the columns. Our cider data is a great example: raw_cider_data ## # A tibble: 288 × 27 ## Sample_Name Temperature Panelist_Code MerlynScale_Ranking Fresh_Apples ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1911 Est. Chilled 001 2.3 1 ## 2 Buskey Chilled 001 3.5 1 ## 3 Eden Chilled 001 2.8 0 ## 4 1911 Est. RT 001 4.2 0 ## 5 Buskey RT 001 2 0 ## 6 Eden RT 001 4 0 ## 7 1911 Est. Chilled 002 3 1 ## 8 Buskey Chilled 002 3.3 0 ## 9 Eden Chilled 002 3.5 1 ## 10 1911 Est. RT 002 4.5 0 ## # ℹ 278 more rows ## # ℹ 22 more variables: Fermented &lt;dbl&gt;, Herbal &lt;dbl&gt;, Dry &lt;dbl&gt;, Spice &lt;dbl&gt;, ## # Fruity &lt;dbl&gt;, Smooth &lt;dbl&gt;, Alcohol &lt;dbl&gt;, Light &lt;dbl&gt;, Sweet &lt;dbl&gt;, ## # Woody &lt;dbl&gt;, Berries &lt;dbl&gt;, Sour &lt;dbl&gt;, Funky &lt;dbl&gt;, FullBodied &lt;dbl&gt;, ## # Metallic &lt;dbl&gt;, Floral &lt;dbl&gt;, Candy &lt;dbl&gt;, Bitter &lt;dbl&gt;, Vomit &lt;dbl&gt;, ## # Earthy &lt;dbl&gt;, Synthetic &lt;dbl&gt;, Liking &lt;dbl&gt; We describe the experimental units in the first 3 columns: Sample_Name, Temperature, and Panelist_Code define a single serving/sample. The rest of the columns describe the measurements or observations we made on that single serving. According to the principles of tidy data, the column names themselves define a sort of meta-variable: what are we recording? We can make this data tidy (and long) by instead storing that meta-variable in one column and the actual measurement in another. The pivot_*() functions are the tools to accomplish this. They are remarkably simple and powerful tools for transforming data from wide to long (and vice-versa) as the analysis demands. long_cider_data &lt;- raw_cider_data %&gt;% pivot_longer(cols = Fresh_Apples:Synthetic, names_to = &quot;cata_variable&quot;, values_to = &quot;checked&quot;) long_cider_data ## # A tibble: 6,336 × 7 ## Sample_Name Temperature Panelist_Code MerlynScale_Ranking Liking ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1911 Est. Chilled 001 2.3 6 ## 2 1911 Est. Chilled 001 2.3 6 ## 3 1911 Est. Chilled 001 2.3 6 ## 4 1911 Est. Chilled 001 2.3 6 ## 5 1911 Est. Chilled 001 2.3 6 ## 6 1911 Est. Chilled 001 2.3 6 ## 7 1911 Est. Chilled 001 2.3 6 ## 8 1911 Est. Chilled 001 2.3 6 ## 9 1911 Est. Chilled 001 2.3 6 ## 10 1911 Est. Chilled 001 2.3 6 ## # ℹ 6,326 more rows ## # ℹ 2 more variables: cata_variable &lt;chr&gt;, checked &lt;dbl&gt; pivot_longer() takes wide data and makes it longer, moving the implicit variable stored in the column names into an explicit variable. It uses a select()-style interface for choosing columns to make longer, and you can specify the names of the new columns you’re creating (if you don’t, column names will be placed in a new name column and the cell values will be placed in a value column). I really like the Data Carpentry animation that shows what is happening in motion: Pivoting data to tidy it, from Data Carpentry. Here, we actually left MerlynScale_Ranking and Liking out of our pivot_longer() because they are going to be dependent variables for our penalty analysis. We also used a pivot_longer() in our berry workflow. long_berry_data &lt;- berry_columns %&gt;% pivot_longer(cols = contains(&quot;overall&quot;), names_to = &quot;hedonic_scale&quot;, values_to = &quot;rating&quot;, values_drop_na = TRUE) long_berry_data %&gt;% select(berry, sample, hedonic_scale, rating) ## # A tibble: 7,507 × 4 ## berry sample hedonic_scale rating ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 raspberry 6 9pt_overall 4 ## 2 raspberry 5 9pt_overall 9 ## 3 raspberry 2 9pt_overall 3 ## 4 raspberry 3 9pt_overall 7 ## 5 raspberry 4 9pt_overall 4 ## 6 raspberry 1 9pt_overall 4 ## 7 raspberry 6 9pt_overall 4 ## 8 raspberry 5 9pt_overall 7 ## 9 raspberry 2 9pt_overall 7 ## 10 raspberry 3 9pt_overall 9 ## # ℹ 7,497 more rows We used the tool a little differently here, however: we wanted to pull all of our hedonic rating data into a single place, note the use of contains() in our pivot_longer() selection. Since each subject only used one hedonic scale in an occasion, our overall data table had blocks of NA values throughout it; we dropped the NA values when pivoting. Now we have longer data that gives us one column for an overall hedonic rating, and another (nominal) column that tells us which scale that value originally came from. Did you notice that we actually pivoted longer twice? The goal of this particular workflow was to produce a penalty analysis, and to do that we are treating the CATA and the hedonic ratings as qualitatively different kinds of outcomes: essentially, CATA becomes the independent variable for this analysis, and hedonic liking becomes the observed outcome. Therefore, we couldn’t pivot all at once. Instead, we first gathered our (now commensurate) ratings using a first pivot, and then gathered our CATA variables using a second. long_berry_data &lt;- long_berry_data %&gt;% pivot_longer(starts_with(&quot;cata_&quot;), names_to = &quot;cata_variable&quot;, values_to = &quot;checked&quot;, names_prefix = &quot;cata_&quot;, values_drop_na = TRUE) long_berry_data ## # A tibble: 159,741 × 7 ## `Subject Code` berry sample hedonic_scale rating cata_variable checked ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1001 raspberry 6 9pt_overall 4 appearance_unev… 0 ## 2 1001 raspberry 6 9pt_overall 4 appearance_miss… 1 ## 3 1001 raspberry 6 9pt_overall 4 appearance_crea… 0 ## 4 1001 raspberry 6 9pt_overall 4 appearance_seedy 0 ## 5 1001 raspberry 6 9pt_overall 4 appearance_brui… 0 ## 6 1001 raspberry 6 9pt_overall 4 appearance_notf… 1 ## 7 1001 raspberry 6 9pt_overall 4 appearance_fresh 0 ## 8 1001 raspberry 6 9pt_overall 4 appearance_good… 0 ## 9 1001 raspberry 6 9pt_overall 4 appearance_good… 0 ## 10 1001 raspberry 6 9pt_overall 4 appearance_none 0 ## # ℹ 159,731 more rows Here, notice we once again drop NA values because some CATA variables only applied to some berries (e.g., raspberries had different CATA attributes than strawberries, natch). We also used a shortcut in pivot_longer() to remove the \"cata_\" prefix from each CATA variable name, purely to make them more readable. While we don’t use pivot_wider() in the flow above, it does the opposite of pivot_longer(): provided with a column of ID variables (like the CATA variables) and a column containing observations, it produces a wider, less tidy data frame. This is most frequently useful when getting data ready for some kind of multivariate analysis, like a regression or SVD. We can see the effects on our long cider data. long_cider_data %&gt;% pivot_wider(names_from = cata_variable, values_from = checked) ## # A tibble: 288 × 27 ## Sample_Name Temperature Panelist_Code MerlynScale_Ranking Liking Fresh_Apples ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1911 Est. Chilled 001 2.3 6 1 ## 2 Buskey Chilled 001 3.5 7 1 ## 3 Eden Chilled 001 2.8 4 0 ## 4 1911 Est. RT 001 4.2 2 0 ## 5 Buskey RT 001 2 7 0 ## 6 Eden RT 001 4 5 0 ## 7 1911 Est. Chilled 002 3 8 1 ## 8 Buskey Chilled 002 3.3 6 0 ## 9 Eden Chilled 002 3.5 7 1 ## 10 1911 Est. RT 002 4.5 3 0 ## # ℹ 278 more rows ## # ℹ 21 more variables: Fermented &lt;dbl&gt;, Herbal &lt;dbl&gt;, Dry &lt;dbl&gt;, Spice &lt;dbl&gt;, ## # Fruity &lt;dbl&gt;, Smooth &lt;dbl&gt;, Alcohol &lt;dbl&gt;, Light &lt;dbl&gt;, Sweet &lt;dbl&gt;, ## # Woody &lt;dbl&gt;, Berries &lt;dbl&gt;, Sour &lt;dbl&gt;, Funky &lt;dbl&gt;, FullBodied &lt;dbl&gt;, ## # Metallic &lt;dbl&gt;, Floral &lt;dbl&gt;, Candy &lt;dbl&gt;, Bitter &lt;dbl&gt;, Vomit &lt;dbl&gt;, ## # Earthy &lt;dbl&gt;, Synthetic &lt;dbl&gt; 2.3.3.3 Split-apply-combine: group_by()/summarize() Many basic data analyses can be described as split-apply-combine: split the data into groups, apply some analysis into groups, and then combine the results. For example, in our raw_berry_data we might want to split the data by each berry sample, calculate the average overall rating and standard deviation of the rating for each, and the generate a summary table telling us these results. Using the filter() and select() commands we’ve learned so far, you could probably cobble together this analysis without further tools. However, tidyverse provides two powerful tools to do this kind of analysis: The group_by() function takes a data table and groups it by categorical values of any column (generally don’t try to use group_by() on a numeric variable) The summarize() function is like mutate() for groups created with group_by(): First, you specify 1 or more new columns you want to calculate for each group Second, the function produces 1 value for each group for each new column We actually use this approach exactly to get our penalty analysis results for both the berry and cider data sets. Before we embark on that, though, let’s quickly cobble together the exact example (means and SDs) to get an intuition for how a split-apply-combine approach works. raw_berry_data %&gt;% # here we are filtering and selecting just to get unstructured line scale # ratings (simply because this is the raw data) select(berry, sample, us_overall) %&gt;% drop_na() %&gt;% # convenience function to remove the NA rows # Now we can *split*: group by berry and by sample group_by(berry, sample) %&gt;% # And now we *apply* a set of summary functions to each group (berry x sample # #) and then *combine* the analyses to get a summary table summarize(mean = mean(us_overall), sd = sd(us_overall), n = n(), se = sd / sqrt(n), ll = mean - 2 * se, ul = mean + 2 * se) ## # A tibble: 23 × 8 ## # Groups: berry [4] ## berry sample mean sd n se ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 blackberry 1 7.60 4.09 98 0.413 6.78 8.43 ## 2 blackberry 2 6.5 3.91 98 0.395 5.71 7.29 ## 3 blackberry 3 8.48 3.93 98 0.397 7.69 9.27 ## 4 blackberry 4 8.86 3.91 98 0.395 8.07 9.65 ## 5 blackberry 5 8.26 4.11 98 0.415 7.43 9.08 ## 6 blueberry 1 9.47 3.25 103 0.321 8.82 10.1 ## 7 blueberry 2 9.30 3.62 103 0.357 8.59 10.0 ## 8 blueberry 3 9.01 3.79 103 0.374 8.26 9.76 ## 9 blueberry 4 8.67 3.67 103 0.361 7.95 9.39 ## 10 blueberry 5 9.23 3.91 103 0.386 8.46 10.0 ## # ℹ 13 more rows Notice that I can request multiple summary functions for each group; I can also use summaries I just defined (like sd or n) in further calculations. Here, we’ve easily calculated a basic Fisher’s LSD table for our means (letting \\(t\\approx2\\)). Now let’s look at what we actually did for our penalty analyses. For the cider data, we needed to calculate the change in mean score for when an attribute was checked or not (typical approach for CATA data). cider_penalty_data &lt;- long_cider_data %&gt;% group_by(cata_variable, checked) %&gt;% summarize(rating = mean(Liking), count = n()) %&gt;% # You can also use mutate() within data that has been *split* by group_by(); # the difference between summarize() and mutate() is that summarize() # collapses each group to a single row. mutate(proportion = count / sum(count)) %&gt;% # We use ungroup() because leaving groups in a data frame can have unexpected # results if we forget that we&#39;ve specified them. ungroup() cider_penalty_data ## # A tibble: 44 × 5 ## cata_variable checked rating count proportion ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Alcohol 0 5.56 178 0.618 ## 2 Alcohol 1 4.91 110 0.382 ## 3 Berries 0 5.18 264 0.917 ## 4 Berries 1 6.71 24 0.0833 ## 5 Bitter 0 5.68 220 0.764 ## 6 Bitter 1 4.10 68 0.236 ## 7 Candy 0 5.25 271 0.941 ## 8 Candy 1 6.24 17 0.0590 ## 9 Dry 0 5.69 177 0.615 ## 10 Dry 1 4.69 111 0.385 ## # ℹ 34 more rows In this case, when we start with our long_cider_data, we have a column for each CATA attribute and another column for whether that attribute is checked. By treating these as variables to group_by() we can get the information we need for penalty analysis: the mean liking rating for each combination of these variables. We also calculated the proportion of times each combination was observed, since sometimes simple penalty analysis can obscure this information. For the berries, we did something similar (although we ignored the proportions) partly to illustrate alternative visualization possibilities, and partly because the larger experimental design made this analysis unwieldy. berry_penalty_data &lt;- long_berry_data %&gt;% group_by(berry, cata_variable, checked) %&gt;% summarize(penalty_lift = mean(rating), count = n()) %&gt;% ungroup() berry_penalty_data ## # A tibble: 170 × 5 ## berry cata_variable checked penalty_lift count ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 blackberry appearance_fresh 0 4.70 518 ## 2 blackberry appearance_fresh 1 5.80 977 ## 3 blackberry appearance_goodcolor 0 4.63 458 ## 4 blackberry appearance_goodcolor 1 5.77 1037 ## 5 blackberry appearance_goodquality 0 4.69 636 ## 6 blackberry appearance_goodquality 1 5.96 859 ## 7 blackberry appearance_goodshapre 0 4.93 708 ## 8 blackberry appearance_goodshapre 1 5.86 787 ## 9 blackberry appearance_misshapen 0 5.63 1048 ## 10 blackberry appearance_misshapen 1 4.92 447 ## # ℹ 160 more rows 2.3.4 Some convenience functions While we have only reviewed what I consider the “basic” functionality of tidyverse for data wrangling, hopefully this gives you a good idea of the powerful and pretty user-friendly tools provided to you through this package. I wanted to mention a few very basic tools that also make tasks typically painful in R easy. 2.3.4.1 Renaming columns Renaming data frames in R is harder than you might think. With the tools we’ve just learned, you might realize that, for example, you could probably use some combination of select() and mutate()/transmute() to rename columns, but I make heavy use of the appropriately-named rename() function to easily change the name of variables: berry_penalty_data %&gt;% rename(penalty = penalty_lift) ## # A tibble: 170 × 5 ## berry cata_variable checked penalty count ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 blackberry appearance_fresh 0 4.70 518 ## 2 blackberry appearance_fresh 1 5.80 977 ## 3 blackberry appearance_goodcolor 0 4.63 458 ## 4 blackberry appearance_goodcolor 1 5.77 1037 ## 5 blackberry appearance_goodquality 0 4.69 636 ## 6 blackberry appearance_goodquality 1 5.96 859 ## 7 blackberry appearance_goodshapre 0 4.93 708 ## 8 blackberry appearance_goodshapre 1 5.86 787 ## 9 blackberry appearance_misshapen 0 5.63 1048 ## 10 blackberry appearance_misshapen 1 4.92 447 ## # ℹ 160 more rows Notice above we do not quote column names. We can also rename() by column position, which is particularly useful when importing files: read_csv(&quot;data/CiderDryness_SensoryDATA.csv&quot;) %&gt;% rename(sample = 1) # This is actually called &quot;Sample_Name&quot; in the .csv ## # A tibble: 288 × 27 ## sample Temperature Panelist_Code MerlynScale_Ranking Fresh_Apples Fermented ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1911 Es… Chilled 001 2.3 1 0 ## 2 Buskey Chilled 001 3.5 1 1 ## 3 Eden Chilled 001 2.8 0 0 ## 4 1911 Es… RT 001 4.2 0 1 ## 5 Buskey RT 001 2 0 1 ## 6 Eden RT 001 4 0 1 ## 7 1911 Es… Chilled 002 3 1 1 ## 8 Buskey Chilled 002 3.3 0 0 ## 9 Eden Chilled 002 3.5 1 0 ## 10 1911 Es… RT 002 4.5 0 0 ## # ℹ 278 more rows ## # ℹ 21 more variables: Herbal &lt;dbl&gt;, Dry &lt;dbl&gt;, Spice &lt;dbl&gt;, Fruity &lt;dbl&gt;, ## # Smooth &lt;dbl&gt;, Alcohol &lt;dbl&gt;, Light &lt;dbl&gt;, Sweet &lt;dbl&gt;, Woody &lt;dbl&gt;, ## # Berries &lt;dbl&gt;, Sour &lt;dbl&gt;, Funky &lt;dbl&gt;, FullBodied &lt;dbl&gt;, Metallic &lt;dbl&gt;, ## # Floral &lt;dbl&gt;, Candy &lt;dbl&gt;, Bitter &lt;dbl&gt;, Vomit &lt;dbl&gt;, Earthy &lt;dbl&gt;, ## # Synthetic &lt;dbl&gt;, Liking &lt;dbl&gt; 2.3.4.2 Reorder rows We often want to reorder the rows in a data frame according to some criteria (usually data-based). Again, a pain in base R, this is made easy using the arrange() function in tidyverse. berry_penalty_data %&gt;% arrange(penalty_lift) ## # A tibble: 170 × 5 ## berry cata_variable checked penalty_lift count ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 blackberry taste_none 1 3.45 105 ## 2 blackberry appearance_notfresh 1 3.76 127 ## 3 raspberry taste_none 1 3.85 103 ## 4 strawberry taste_none 1 4.04 121 ## 5 raspberry taste_fermented 1 4.04 150 ## 6 strawberry taste_fermented 1 4.06 303 ## 7 blackberry taste_fermented 1 4.08 274 ## 8 blueberry taste_none 1 4.08 94 ## 9 blackberry taste_berry 0 4.21 702 ## 10 blueberry taste_fermented 1 4.27 147 ## # ℹ 160 more rows We can use either the - (the subtraction operator) or the convenience function desc() to reverse columns in arrange(). We can also sort by multiple criteria, for example here we can sort by the observed CATA 0/1 descending (highest first), and then break ties by the rating, sorting ascending (lowest first). cider_penalty_data %&gt;% arrange(-count, rating) ## # A tibble: 44 × 5 ## cata_variable checked rating count proportion ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Candy 0 5.25 271 0.941 ## 2 Vomit 0 5.44 271 0.941 ## 3 Berries 0 5.18 264 0.917 ## 4 Synthetic 0 5.56 258 0.896 ## 5 Metallic 0 5.47 257 0.892 ## 6 Earthy 0 5.42 254 0.882 ## 7 FullBodied 0 5.25 253 0.878 ## 8 Woody 0 5.37 248 0.861 ## 9 Funky 0 5.67 241 0.837 ## 10 Herbal 0 5.29 236 0.819 ## # ℹ 34 more rows Finally, arrange() will respect groups, so we can sort our penalties within our berries to see what matters most: berry_penalty_data %&gt;% group_by(berry) %&gt;% arrange(-penalty_lift) %&gt;% slice_head(n = 5) ## # A tibble: 20 × 5 ## # Groups: berry [4] ## berry cata_variable checked penalty_lift count ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 blackberry taste_fruity 1 6.62 510 ## 2 blackberry taste_berry 1 6.49 793 ## 3 blackberry taste_floral 1 6.20 248 ## 4 blackberry appearance_goodquality 1 5.96 859 ## 5 blackberry appearance_goodshapre 1 5.86 787 ## 6 blueberry taste_berry 1 6.78 1079 ## 7 blueberry taste_fruity 1 6.77 761 ## 8 blueberry taste_peachy 1 6.36 286 ## 9 blueberry appearance_goodquality 1 6.27 1191 ## 10 blueberry appearance_fresh 1 6.25 1248 ## 11 raspberry taste_candy 1 6.94 323 ## 12 raspberry taste_fruity 1 6.85 1029 ## 13 raspberry taste_tropical 1 6.78 417 ## 14 raspberry taste_berry 1 6.65 1353 ## 15 raspberry appearance_goodquality 1 6.47 1069 ## 16 strawberry taste_fruity 1 6.56 782 ## 17 strawberry taste_berry 1 6.51 941 ## 18 strawberry taste_caramel 1 6.50 74 ## 19 strawberry appearance_goodquality 1 6.29 619 ## 20 strawberry taste_peachy 1 6.28 157 2.3.4.3 Subset data Note the slice_head() function above: this gives us the first 5 rows (of each group, because we used group_by()) in the data set. The family of slice_*() functions is very useful for subsetting data. 2.4 Saving your data Often, you will have an ugly, raw data file. You want to clean up this data file: remove junk variables, rename columns, omit outliers, and have something that is actually workable. Sometimes, you create a new intermediate product (say, a penalty-analysis table) that you’d like to be able to share and work with elsewhere. Now, you know how to do all that in R, often with fewer clicks and less effort than in Excel or other WYSIWYG tool. But once you restart your R session, you will need to rerun this workflow, and you can’t access your data products in other software. To save this work, you can use write.csv() or readr::write_csv() and its relatives (e.g., functions like write.file()). These will create or overwrite a file in the directory location you specify. # We will keep in the tidyverse idiom with readr::write_csv() write_csv(x = berry_penalty_data, file = &quot;data/berry-penalty-data.csv&quot;) Sometimes, we want to be able to save R data for re-loading later. It’s good to do this explicitly, rather than relying on something like RStudio’s version of autosaving (which we’ve turned off for you at the beginning of this tutorial). You might want to do this instead of write_csv() because: You have non-tabular data (lists, tensors, ggplots, etc) You are saving the output of time-consuming workflows and want to be able to start again without re-running those workflows You want to bundle a lot of objects together into a single file for yourself or other R users If you want to save a single R object, the write_rds() function saves an object into a native R data format: .rds. This uses syntax similar to write_csv(): berry_penalty_data %&gt;% write_rds(file = &quot;data/berry-penalty-data.rds&quot;) Often, though, it can be helpful to save multiple R objects so that a workplace can be restored. In this case, the generic save() function will save a list of R objects provided as symbolic names into a file of format .RData, which can be restored with load(). save(long_berry_data, long_cider_data, file = &quot;data/long-data-objects.RData&quot;) rm(long_berry_data, long_cider_data) load(file = &quot;data/long-data-objects.RData&quot;) This can be very helpful for sharing data. 2.4.1 A note on replicability In order to make sure that your data are replicable, you should always keep your raw data and the script/code that transforms that data into your cleaned form. That way, when (not if) you discover a couple minor errors, you can go back and fix them, and you will not be stuck trying to remember how you overwrote this data in the first place. This will also protect you if, in the future, someone looks at your data and asks something like “but where did these means come from?” 2.5 Wrap up This is just a taste of the quality-of-life data wrangling tools available in tidyverse. To learn more, you can look into some of the resources we’ve linked here (in particular the R for Data Science handbook), some of our previous workshops on the topic, to see how these tools can be applied to sensory data, or my recently created R Opus v2, which applies these tools to a variety of common sensory analyses. "],["the-basics-of-plotting-with-ggplot2.html", "3 The basics of plotting with ggplot2 3.1 Your first ggplot() 3.2 The aes() function and mapping = argument 3.3 Adding layers with geom_*() functions 3.4 Arguments inside and outside of aes() 3.5 Some further reading", " 3 The basics of plotting with ggplot2 Base R includes extremely powerful utilities for data visualization, but most modern applications make use of the tidyverse package ggplot2. A quick word about base R plotting–I don’t mean to declare that you can’t use base R plotting for your projects at all, and I have published several papers using base R plots. Particularly as you are using R for your own data exploration (not meant for sharing outside your team, say), base utilities like plot() will be very useful for quick insight. ggplot2 provides a standardized, programmatic interface for data visualization, in contrast to the piecemeal approach common to base R graphics plotting. This means that, while the syntax itself can be challenging to learn, syntax for different tasks is linked by a common vocabulary, and differs in logical and predictable ways. Together with other tidyverse principles (like select() and filter() approaches), ggplot2 makes it easy to make publication-quality visualizations with relative ease. In general, ggplot2 works best with data in “long” or “tidy” format, such as that resulting from the output of pivot_longer(). The The schematic elements of a ggplot are as follows: # The ggplot() function creates your plotting environment. We usually save it to a variable in R so that we can use the plug-n-play functionality of ggplot without retyping a bunch of nonsense p &lt;- ggplot(mapping = aes(x = &lt;a variable&gt;, y = &lt;another variable&gt;, ...), data = &lt;your data&gt;) # Then, you can add various ways of plotting data to make different visualizations. p + geom_&lt;your chosen way of plotting&gt;(...) + theme_&lt;your chosen theme&gt; + ... In graphical form, the following diagram (from VT Professor JP Gannon) gives an intuition of what is happening: Basic ggplot mappings. Color boxes indicate where the elements go in the function and in the plot. 3.1 Your first ggplot() Our cider data is already relatively tidy and is much easier to visually inspect, so we will be primarily using it in this section. Let’s begin by making an example ggplot() to demonstrate how it works. # We start with our data and pipe it into ggplot raw_cider_data %&gt;% # Here we set up the base plot ggplot(mapping = aes(x = MerlynScale_Ranking, y = Liking)) + # Here we tell our base plot to add points geom_point() This doesn’t look all that impressive–partly because the data being plotted itself isn’t that sensible, and partly because we haven’t made many changes. But before we start looking into that, let’s break down the parts of this command. 3.2 The aes() function and mapping = argument The ggplot() function takes two arguments that are essential, as well as some others you’ll rarely use. The first, data =, is straightforward, and you’ll usually be passing data to the function at the end of some pipeline using %&gt;% The second, mapping =, is less clear. This argument requires the aes() function, which can be read as the “aesthetic” function. The way that this function works is quite complex, and really not worth digging into here, but I understand it in my head as telling ggplot() what part of my data is going to connect to what part of the plot. So, if we write aes(x = MerlynScale_Ranking), we can read this in our heads as “the values of x will be mapped from the ‘MerlynScale_Ranking’ column”. This sentence tells us the other important thing about ggplot() and the aes() mappings: mapped variables each have to be in their own column. This is another reason that ggplot() requires tidy data. 3.3 Adding layers with geom_*() functions In the above example, we added (literally, using +) a function called geom_point() to the base ggplot() call. This is functionally a “layer” of our plot, that tells ggplot2 how to actually visualize the elements specified in the aes() function–in the case of geom_point(), we create a point for each row’s combination of x = MerlynScale_Ranking and y = Liking. raw_cider_data %&gt;% select(MerlynScale_Ranking, Liking) ## # A tibble: 288 × 2 ## MerlynScale_Ranking Liking ## &lt;dbl&gt; &lt;dbl&gt; ## 1 2.3 6 ## 2 3.5 7 ## 3 2.8 4 ## 4 4.2 2 ## 5 2 7 ## 6 4 5 ## 7 3 8 ## 8 3.3 6 ## 9 3.5 7 ## 10 4.5 3 ## # ℹ 278 more rows There are many geom_*() functions in ggplot2, and many others defined in other accessory packages. These are the heart of visualizations. We can swap them out to get different results: raw_cider_data %&gt;% ggplot(mapping = aes(x = MerlynScale_Ranking, y = Liking)) + geom_smooth() Here we fit a smoothed line to our data using the default methods in geom_smooth() (which in this case heuristically defaults to a spline model with LOESS smoothing, but could be linear, GAM, etc). We can also combine layers, as the term “layer” implies: raw_cider_data %&gt;% ggplot(mapping = aes(x = MerlynScale_Ranking, y = Liking)) + geom_jitter() + # add some random noise to show overlapping points geom_smooth() Note that we don’t need to tell either geom_smooth() or geom_jitter() what x and y are–they “inherit” them from the ggplot() function to which they are added (+), which defines the plot itself. What other arguments can be set to aesthetics? Well, we can set other visual properties like color, size, transparency (called “alpha”), and so on. For example, let’s try to look at whether there is a relationship between whether a cider is perceived as “Dry” through CATA, measured as “Dry” (low values) on the Merlyn Scale, and overall liking. raw_cider_data %&gt;% mutate(Dry = as.factor(Dry)) %&gt;% ggplot(mapping = aes(x = MerlynScale_Ranking, y = Liking, color = Dry)) + geom_jitter(alpha = 1/2) + scale_color_manual(values = c(&quot;darkblue&quot;, &quot;darkorange&quot;)) + theme_bw() We can see that most of the orange dots are to the left side of the figure (associated with lower Merlyn scale ratings), and that most of th3e blue dots are to the right (associated with higher Merlyn Scale ratings). It’s hard to make sense of patterns of liking in this visualization, but it looks like “Dry” CATA checks may have somewhat lower liking ratings overall. 3.4 Arguments inside and outside of aes() In the last plot, we saw an example in the geom_jitter(alpha = 1/2) function of setting the alpha (transparency) aesthetic element directly, without using aes() to map a variable to this aesthetic. That is why this is not wrapped in the aes() function. In ggplot2, this is how we set aesthetics to fixed values. If we had a value we wanted to map transparency to, we would set aes(alpha = &lt;variable&gt;). In this dataset, I can’t think of a good option for alpha, but note that we can set any variable in these two ways: # First, here is the previous figure, showing how we can set aesthetics raw_cider_data %&gt;% mutate(Dry = as.factor(Dry)) %&gt;% ggplot(aes(x = MerlynScale_Ranking, y = Liking)) + # We can set new aes() mappings in individual layers, as well as the plot itself geom_jitter(aes(color = Dry)) + scale_color_manual(values = c(&quot;darkblue&quot;, &quot;darkorange&quot;)) + theme_bw() # And now we manually set a color for our points: note this means our color # WON&#39;T change with different values of a variable. raw_cider_data %&gt;% mutate(Dry = as.factor(Dry)) %&gt;% ggplot(aes(x = MerlynScale_Ranking, y = Liking)) + # notice we no longer use aes() below, and color no longer matches `Dry` geom_jitter(color = &quot;darkorange&quot;) + theme_bw() 3.4.1 Using theme_*() to change visual options quickly In the last several plots, notice that we have changed from the default (and to my mind unattractive) grey background of ggplot2 to a black and white theme. This is by adding a theme_bw() call to the list of commands. ggplot2 includes a number of default theme_*() functions, and you can get many more through other R packages. They can have subtle to dramatic effects: raw_cider_data %&gt;% ggplot(aes(x = MerlynScale_Ranking, y = Liking)) + geom_jitter() + theme_void() You can edit every last element of the plot’s theme using the base theme() function, which is powerful but a little bit tricky to use. raw_cider_data %&gt;% ggplot(aes(x = MerlynScale_Ranking, y = Liking)) + geom_jitter() + theme_bw() + # we use theme() to remove grid lines, for example theme(panel.grid = element_blank()) Most of the use of theme() involves functions names as element_*(). When we remove elements, for example, we use element_blank() (not, for example, NA or NULL as we typically would in other parts of R). Finally, we can set default themes for a particular script using the theme_set() function. We can also use this to set custom defaults: theme_set( theme_bw() + theme(panel.grid.minor = element_blank()) ) raw_cider_data %&gt;% ggplot(aes(x = MerlynScale_Ranking, y = Liking)) + geom_jitter() All plots from here on will default to the theme_bw() theme, with the “minor” grid lines removed for a cleaner grid look. 3.4.2 Changing aesthetic elements with scale_*() functions Finally, say we didn’t like the default color set for the points. How can we manipulate the colors that are plotted? The way in which mapped, aesthetic variables are assigned to visual elements is controlled by the scale_*() functions. In my experience, the most frequently encountered scales are those for color: either scale_fill_*() for solid objects (like the bars in a histogram) or scale_color_*() for lines and points (like the outlines of the histogram bars). Scale functions work by telling ggplot() how to map aesthetic variables to visual elements. You may have noticed that I added a scale_color_manual() function to the end of several plots above. This function lets me manually specify the colors that are assigned to each colored element. p &lt;- raw_cider_data %&gt;% mutate(Dry = as.factor(Dry)) %&gt;% # This block gets us a subset of beer styles for clear visualization ggplot(mapping = aes(x = Liking)) + geom_density(mapping = aes(fill = Dry), alpha = 1/3, color = &quot;transparent&quot;) p We can take a saved plot (like p) and use scales to change how it is visualized. p + scale_fill_viridis_d() ggplot2 has a broad range of built-in options for scales, but there are many others available in add-on packages that build on top of it. The scale_*_viridis_*() functions use a package callled viridis that provides (theoretically) color-blind safe colors for both continuous (gradient) and categorical (discrete) mappings, but I do find that their defaults (using light colors like yellow on one end of the scale) are hard to see for anyone! As we saw above, you can also build your own scales using the scale_*_manual() functions, in which you give a vector of the same length as your mapped aesthetic variable in order to set up the visual assignment. That sounds jargon-y, so here is an example: # We&#39;ll pick 14 random colors from the colors R knows about random_colors &lt;- print(colors()[sample(x = 1:length(colors()), size = 10)]) ## [1] &quot;gray0&quot; &quot;palevioletred&quot; &quot;yellow2&quot; &quot;mediumpurple4&quot; ## [5] &quot;orange4&quot; &quot;seagreen4&quot; &quot;dodgerblue&quot; &quot;grey90&quot; ## [9] &quot;lightseagreen&quot; &quot;mediumorchid1&quot; p + scale_fill_manual(values = random_colors) 3.4.3 Finally, facet_*() The last powerful tool I want to show off is the ability of ggplot2 to make what Edward Tufte called “small multiples”: breaking out the data into multiple, identical plots by some categorical classifier in order to show trends more effectively. So far we’ve seen how to visualize the overall liking of ciders in our small data set by the Merlyn Scale Ranking, and how to assign color, transparency, and fill to other attributes. We can use such an approach to get a quick picture of the CATA selections for each cider in a clear, easy to see visualization: raw_cider_data %&gt;% pivot_longer(Fresh_Apples:Synthetic) %&gt;% group_by(Sample_Name, Temperature, name) %&gt;% summarize(total = sum(value)) %&gt;% ggplot(aes(x = interaction(Sample_Name, Temperature), y = total)) + geom_col(aes(fill = Sample_Name)) + scale_fill_manual(values = wesanderson::wes_palettes$FantasticFox1) + coord_flip() + facet_wrap(~name, ncol = 6) + labs(x = NULL, y = NULL, fill = NULL) + theme(legend.position = &quot;top&quot;) We can see that overall for the most frequently used attributes, the serving temperature doesn’t matter (and for the most part there is some reassuring consistency in the use of terms to describe each cider at different temperatures). But in the previous part of this workshop, we showed much more complex plots for our berry data, which showed the same plot broken up by a classifying variable: this is called “faceting”. Let’s return from our cider data to our berry data in order to finally complete the workflow I showed in the beginning of the workshop. Now we are prepared to walk through the entire workflow # First we wrangle our data using the tools we&#39;ve learned to get penalties/lifts # for each attributes berry_penalty_analysis_data &lt;- berry_long_cata %&gt;% group_by(berry, cata_variable, checked) %&gt;% summarize(penalty_lift = mean(rating), count = n()) %&gt;% ungroup() p1_berry_penalty &lt;- # We start by widening our data just a bit, and use a function to give some # better names to our mean values for when an attribute it checked (1) or not # (0). berry_penalty_analysis_data %&gt;% select(-count) %&gt;% pivot_wider(names_from = checked, values_from = penalty_lift, names_prefix = &quot;checked_&quot;) %&gt;% # Then we actually calculate the penalty/lift: what is the difference in the # mean liking when an attribute is checked or not? group_by(berry, cata_variable) %&gt;% summarize(penalty_lift = checked_1 - checked_0) %&gt;% # We have two kinds of CATA attibutes: visual assessment and by-mouth # assessment. It would be nice to keep track. separate(cata_variable, into = c(&quot;mode&quot;, &quot;variable&quot;), sep = &quot;_&quot;) %&gt;% # Fix a typo mutate(mode = str_replace(mode, &quot;appearane&quot;, &quot;appearance&quot;)) %&gt;% mutate(mode = case_when(mode == &quot;taste&quot; ~ &quot;(T)&quot;, mode == &quot;appearance&quot; ~ &quot;(A)&quot;)) %&gt;% unite(variable, mode, col = &quot;cata_variable&quot;, sep = &quot; &quot;) %&gt;% # We are using a function from tidytext that makes faceting the final figure # easier: reorder_within() makes a set of factors able to be ordered # differently within another variable. In this case, we have different # attributes and different penalties within each berry by design mutate(cata_variable = tidytext::reorder_within(x = cata_variable, by = penalty_lift, within = berry)) %&gt;% #And finally we plot! ggplot(mapping = aes(x = cata_variable, y = penalty_lift)) + geom_col(aes(fill = penalty_lift), color = &quot;white&quot;, show.legend = FALSE) + facet_wrap(~berry, scales = &quot;free&quot;, nrow = 1) + # To take advantage of our newly reordered factors, we also need to use the # matching tidytext::scale_x_reordered() function tidytext::scale_x_reordered() + coord_flip() + theme_classic() + scale_fill_gradient(low = &quot;tan&quot;, high = &quot;darkgreen&quot;) + labs(x = NULL, y = NULL, title = &quot;Penalty / Lift Analysis&quot;, subtitle = &quot;displays the mean difference (within berries) for when a CATA variable is checked\\nor un-checked&quot;) # Let&#39;s save it so we can come back to it later: save(p1_berry_penalty, file = &quot;data/goal-plot.RData&quot;) p1_berry_penalty We can see that the 2 most important attributes for driving liking are the same across all 4 berries, but that the highest penalty is different across them. 3.5 Some further reading This has been a lightning tour of ggplot2 as preparatory material; it barely scratches the surface. We’re going to dig into some further tools that you can use for common sensory visualizations, but we’ve learned all of these tricks from the following resources (as well as a lot of work on Stack Overflow/Exchange): Kieran Healy’s “Data Visualization: a Practical Introduction”. The plotting section of R for Data Science. Hadley Wickham’s core reference textbook on ggplot2. "],["using-ggplot-with-other-packages.html", "4 Using ggplot with Other Packages 4.1 Data for the rest of the tutorial 4.2 New geom_*()s and stat_*()s 4.3 New theme_*()s and scale_*()s 4.4 Modifying ggplot()s made by other packages 4.5 Combining Plots 4.6 Finding New Packages", " 4 Using ggplot with Other Packages As you might have noticed, we had you download more packages than just ggplot2 for this tutorial. ggplot2 is a framework and will help you make many standard plots, but it can’t do everything. Or, sometimes, you may not want to use it to do everything yourself. Packages meant to work with ggplot2 to more easily make specific kinds of visualizations are also called ggplot extensions. The four most common kinds of ggplot extensions are: Packages that add geom_*()s or stat_*()s for new kinds of plots Packages that add theme_*()s and scale_*()s for specific color or style needs Packages that make ggplot objects, so you never write ggplot() yourself Packages that combine multiple plots in various ways You can view many of these extensions on the tidyverse website (where you’ll also see many examples that fall into multiple of these categories or don’t fit into the categories here at all). 4.1 Data for the rest of the tutorial In order to dive into the actual visualization parts of a data analysis workflow, we’re going to skip over most of the intensive data wrangling from here on out. In addition to the existing raw_berry_data and raw_cider_data we’ve read in previously with read_csv(), let’s use load(\"data/cleaned-data.RData\") to pull in 6 tibbles of data at various intermediate stages. If you’re curious, we’ve included all of the code we used to wrangle these tibbles in the script datawrangling.R, but for now, let’s just load them in and use the FactoMineR package to get some product coordinates. load(&quot;data/cleaned-data.RData&quot;) cider_contingency %&gt;% FactoMineR::CA(graph = FALSE) -&gt; ca_cider berry_mfa_summary %&gt;% FactoMineR::MFA(group = c(sum(str_detect(colnames(berry_mfa_summary), &quot;^cata_&quot;)), sum(str_detect(colnames(berry_mfa_summary), &quot;^liking_&quot;))), type = c(&quot;f&quot;,&quot;s&quot;), graph = FALSE, name.group = c(&quot;CATA&quot;,&quot;Liking&quot;)) -&gt; berry_mfa_res save(ca_cider, berry_mfa_res, file = &quot;data/svd-results.RData&quot;) 4.2 New geom_*()s and stat_*()s If you want to label each individual point in the plotting area using text, rather than some symbol or color that indicates the legend off to the side, you can do this using the base ggplot2 functions geom_text() and geom_label(): #Let&#39;s use the cider CA example from before. #We can make our own plots from the coordinates. ca_cider$col$coord %&gt;% as_tibble(rownames = &quot;Attribute&quot;) %&gt;% ggplot(aes(x = `Dim 1`, y = `Dim 2`, label = Attribute)) + theme_bw() -&gt; ca_cider_termplot ca_cider_termplot + geom_text() ca_cider_termplot + geom_label() But, as you can see, the text starts to overlap itself quickly even with only a small handful of attributes. The extension I personally use most often, to make crowded plots like this more readable, is the package ggrepel, which adds new geom_text_repel() and geom_label_repel(). ca_cider_termplot + ggrepel::geom_label_repel() They’re almost identical to the normal text and label geom_*()s, but they use an iterative algorithm to push each piece of text away from the other text and unrelated points or geom_()s, while being pulled towards the point being labeled. It is not deterministic, so it will be slightly different each time you run the code (try it now!) unless you use set.seed() first or set seed = *** when adding geom_*_repel(). Even with a set seed, changing the plot size or adding geom_*()s to the plot will also slightly change the locations of the labels, so if you’re going to try and find a seed that works well for your data, you should be checking it on your final exported plot at the publication resolution (we’ll talk about that next chapter). ca_cider_termplot + ggrepel::geom_label_repel(seed = 12345) There are many settings you can play with to adjust these forces, how far a label has to move for a line to show up, whether any labels are left off in dense areas, and how long it tries to find a solution. And, randomly, the ability to give each letter-shape a border in a different color, which seems to be totally undocumented in the help files. It can be useful if there are other, multi-colored geom_*()s in the background. raw_cider_data %&gt;% mutate(Product = str_c(Sample_Name, Temperature, sep = &quot; &quot;)) %&gt;% group_by(Product) %&gt;% summarize(Liking = mean(Liking)) %&gt;% left_join(ca_cider$row$coord %&gt;% as_tibble(rownames = &quot;Product&quot;)) %&gt;% rename_with(~ str_replace_all(.x, &quot; &quot;, &quot;.&quot;)) -&gt; ca_cider_productcoord #This is NOT a statistically sound preference model, this is just for demonstration ca_cider_prefmod &lt;- lm(Liking ~ Dim.1 * Dim.2, data = ca_cider_productcoord) expand.grid(Dim.1 = seq(min(ca_cider$col$coord[, &quot;Dim 1&quot;]) - 0.1, max(ca_cider$col$coord[, &quot;Dim 1&quot;]) + 0.1, by = 0.01), Dim.2 = seq(min(ca_cider$col$coord[, &quot;Dim 2&quot;]) - 0.1, max(ca_cider$col$coord[, &quot;Dim 2&quot;]) + 0.1, by = 0.01)) %&gt;% mutate(., Liking = predict(ca_cider_prefmod, newdata = .)) -&gt; ca_cider_prefinterp ca_cider_termplot + geom_contour_filled(aes(x = Dim.1, y = Dim.2, z = Liking, fill = after_stat(level)), inherit.aes = FALSE, data = ca_cider_prefinterp) + scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0)) + ggrepel::geom_text_repel(size = 6, color = &quot;white&quot;, bg.color = &quot;grey7&quot;) Another useful tool for visualizing any ordinal/binned data (e.g., the 9-point hedonic scale) at scale is the geom_beeswarm() and geom_quasirandom() from the ggbeeswarm package, which are similar to geom_jitter() but intended for looking at a single numeric variable at a time, possibly across multiple categories. They limit the jitter to a single direction and ensure that no points are overlapping (or, in the case of geom_quasirandom(), that there’s a uniform amount of overlap) so you can get a more accurate picture of the density, but take up less space than many faceted geom_histogram()s (at least for the same amount of fine-tuning). #The jitter plot is actually not very helpful with this many points berry_long_liking %&gt;% ggplot(aes(x = Scale, y = Liking, color = Scale)) + geom_jitter() + facet_wrap(~ Attribute) + theme_bw() #geom_beeswarm() will also have the same problem, but geom_quasirandom() #visualizes the density at each &quot;bin&quot; without us having to specify bins. #So these are easy to compare berry_long_liking %&gt;% ggplot(aes(x = Scale, y = Liking, color = Scale)) + ggbeeswarm::geom_quasirandom() + facet_wrap(~ Attribute) + theme_bw() If you want to easily add circles and ellipses to a plot (say, the unit circle or a confidence ellipse), you’ll probably want to install the ggforce package and use geom_circle() or geom_ellipse(), respectively. berry_mfa_res$quanti.var$coord %&gt;% as_tibble(rownames = &quot;Modality&quot;) %&gt;% ggplot() + geom_segment(aes(x = 0, y = 0, xend = Dim.1, yend = Dim.2), arrow = arrow()) + ggforce::geom_circle(aes(x0 = 0, y0 = 0, r = 1), color = &quot;blue&quot;) + ggrepel::geom_text_repel(aes(x = Dim.1, y = Dim.2, label = Modality)) + theme_bw() + theme(aspect.ratio = 1) 4.3 New theme_*()s and scale_*()s Most of the additional geom_*()s in ggplot2 extensions involve some sort of calculation, so the confidence that you’re using someone else’s algorithm that’s (hopefully!) been double-checked is a real benefit. You’ve already seen how to change the way your plots look with theme() one argument at a time, and how to set scale_*_manual() if you have the exact colors or color range that you want. So there’s nothing these prettying-up packages will do that you can’t do yourself, but there are a huge number of ggplot2 extensions that include some version of a no-gridline minimal theme for convenience. Such as: berry_long_liking %&gt;% ggplot(aes(x = Scale, y = Liking, color = Scale)) + ggbeeswarm::geom_quasirandom() + facet_wrap(~ Attribute) + cowplot::theme_minimal_hgrid() Packages that added scale_*()s used to be one of the most common kinds of ggplot extensions (because, as you’ll notice, the above figure with the default color scale is not red-green colorblind friendly), but the most popular scales now come with ggplot2 itself. RColorBrewer’s colorblind- and printer-friendly palettes for categorical data are now available in ggplot2::scale_*_brewer_*(), and you’ve already seen us use the viridis color palettes in ggplot2::scale_*_viridis_*(). The viridis color scales can be used for categorical data, if you use the _d() versions, but they were designed for ordinal and binned data, since some colors will seem more related than others. See Chapter 4 and Chapter 19 of Claus O. Wilke’s book Fundamentals of Data Visualization. 4.4 Modifying ggplot()s made by other packages So far in this chapter, we’ve been making all of the plots with a call to ggplot() and then adding on geoms, themes, labels, scales, and facets with +. But we’ve also been able to save our plots to variables partway through and then keep adding things to the saved plots. This is an incredibly useful difference from the way plots work in base R. Some packages utilize ggplot2 by making a whole plot for you with their own internal call to ggplot(), which means that you can treat it like any other ggplot for the sake of customizing. Most packages which can save a whole plot to a variable or output several plots in a list use ggplot() to do so. #FactoMineR uses ggplot for its internal plotting, #Which is why we can assign the output to a variable #and not see the plot right away #(although the CA() function will also display several plots by default) cider_contingency %&gt;% FactoMineR::CA(graph = FALSE) %&gt;% FactoMineR::plot.CA() -&gt; ca_cider_biplot_facto #The ca package, meanwhile, uses base plotting. #You can tell because it prints this plot immediately. cider_contingency %&gt;% ca::ca() %&gt;% ca::plot.ca() -&gt; ca_cider_biplot_green You can see that the last code chunk only output one plot right away, but we can confirm our suspicions with the base R class() function. class(ca_cider_termplot) # Made with ggplot() ourselves ## [1] &quot;gg&quot; &quot;ggplot&quot; class(ca_cider_biplot_facto) # Made with ggplot-based FactoMineR ## [1] &quot;gg&quot; &quot;ggplot&quot; class(ca_cider_biplot_green) # Made with ca::ca(), not a plot at all ## [1] &quot;list&quot; ca_cider_biplot_green # It&#39;s two tables of coordinates! ## $rows ## Dim1 Dim2 ## 1911 Est. Chilled -0.30922746 0.02323046 ## 1911 Est. RT -0.33096663 0.04492088 ## Buskey Chilled 0.01508206 -0.16463573 ## Buskey RT 0.19222871 -0.19341072 ## Eden Chilled 0.22460300 0.13702229 ## Eden RT 0.20122093 0.14661009 ## ## $cols ## Dim1 Dim2 ## Fresh_Apples -0.30305451 0.08260444 ## Fermented 0.05136995 -0.11123214 ## Herbal 0.27953814 0.05798442 ## Dry 0.09068713 -0.09458987 ## Spice 0.09194648 -0.15607561 ## Fruity -0.26360780 0.04401256 ## Smooth -0.23141023 -0.16865980 ## Alcohol 0.08456228 -0.05135981 ## Light -0.13444990 -0.13768159 ## Sweet -0.13152453 -0.06963735 ## Woody 0.32164765 0.18574435 ## Berries -0.38694032 0.08324652 ## Sour -0.03153644 0.19917586 ## Funky 0.56153039 -0.01014260 ## FullBodied -0.01727177 -0.10673686 ## Metallic 0.13770506 0.36391448 ## Floral 0.05665116 -0.01517803 ## Candy -0.73752932 0.35245085 ## Bitter 0.17535866 -0.02812715 ## Vomit 0.43823154 0.03719609 ## Earthy 0.43043925 -0.06405187 ## Synthetic 0.35094003 0.33924051 What this means is that we can look at the FactoMineR-made plot we’ve saved to ca_cider_biplot_facto: ca_cider_biplot_facto And we can still change up many of the elements by adding additional elements, although you’re likely to get some weird warning messages and some silent errors. (The ggrepel error message is actually just because there are too many geom_text_repel() labels close-together in a small plots, because expanding xlim() crowds everything in the center of the plot.) ca_cider_biplot_facto + theme(panel.grid = element_blank(), # Removes the axis lines plot.title = element_blank()) + # Removes the title xlim(-1,1) + # Extends the x limits, with a warning scale_color_brewer(type = &quot;qual&quot;, palette = &quot;Dark2&quot;) ## Scale for x is already present. ## Adding another scale for x, which will replace the existing scale. # Silently fails to change the color scale You can’t just + scale_color_*() to a FactoMineR plot, because the ggplot already has a non-default color scheme and adding a second color scale does nothing. If you look at the help file for ?FactoMineR::plot.CA, you can set several styling parameters when you’re making the plot, and you can remake it as many times as you need, but doing so does have significantly less flexibility than the approach to plotting we’ve outlined in this workshop. We also can’t go back and adjust the parameters passed to geom_text_repel() after the fact, even though we can tell from the warning messages that that’s the package being used to put the attribute and product names onto the biplot. It will almost always be possible to add more geom_*()s to plots made by other packages, as long as you don’t mind them being added on top of any existing elements in the plot. liking_arrow &lt;- data.frame(x1 = 0, y1 = 0, x2 = -0.4, y2 = -0.1, text = &quot;Liking&quot;) ca_cider_biplot_facto + geom_segment(aes(x= x1, y = y1, xend = x2, yend = y2), color = &quot;orange&quot;, arrow = arrow(length = unit(0.03, &quot;npc&quot;)), linewidth = 1, data = liking_arrow) + geom_text(aes(x = x2, y = y2, label = text), color = &quot;orange&quot;, hjust = &quot;outward&quot;, vjust = &quot;outward&quot;, fontface = &quot;italic&quot;, data = liking_arrow) If you desperately need to change a scale or reorder geom_*()s from an existing ggplot in a hurry, look into the gginnards package. 4.5 Combining Plots You’ve already seen how to facet_*() plots to view “small multiple” plots side-by side: raw_cider_data %&gt;% pivot_longer(Fresh_Apples:Synthetic) %&gt;% group_by(Sample_Name, Temperature, name) %&gt;% summarize(total = sum(value)) %&gt;% ggplot(aes(x = interaction(Sample_Name, Temperature), y = total)) + geom_col(aes(fill = Sample_Name)) + scale_fill_manual(values = wesanderson::wes_palettes$FantasticFox1) + coord_flip() + labs(x = NULL, y = NULL, fill = NULL) + theme_bw() + theme(legend.position = &quot;top&quot;, panel.grid = element_blank()) -&gt; cider_count_plot cider_count_plot + facet_wrap(~name, ncol = 6) This works very well whenever you have multiple plots using the same geom_*()s that you want to show on the same axes, and you can even adjust the axis limits from facet to facet using scales = \"free*\": cider_count_plot + facet_wrap(~name, ncol = 6, scales = &quot;free_x&quot;) # Each plot now has a different x-axis Not that we’d argue you should here. Also, take note that the x in free_x refers to the horizontal axis in the final plot, after the coord_flip(), and not the x aesthetic we set in the ggplot() call. But if you have different plot types entirely (different data sources, different geom_()s, or different categorical axes) that you want to place side-by-side, say a loading plot and the product map resulting from a PCA or MFA, you’re going to need something to paste together multiple ggplot_()s. The easiest way to do this is using patchwork, which will work on ggplots you’ve made yourself or with ones made by packages like FactoMineR. When you have patchwork loaded, the + operator will put two plots side-by-side: library(patchwork) plot(berry_mfa_res, choix = &quot;var&quot;) + plot(berry_mfa_res, partial = &quot;all&quot;) And the / operator will arrange two plots vertically: plot(berry_mfa_res, choix = &quot;var&quot;) / plot(berry_mfa_res, partial = &quot;all&quot;) The advantage of doing this with a package like patchwork, rather than saving separate images, is that it aligns all of the plot areas precisely and that they will more easily move or rearrange certain plot elements like legends and axis labels. plot(berry_mfa_res, choix = &quot;var&quot;) + plot(berry_mfa_res, partial = &quot;all&quot;) + plot_layout(guides = &quot;collect&quot;) &amp; theme(plot.title = element_blank(), legend.position = &quot;bottom&quot;) The &amp; operator lets you add elements like themes or annotations to all of the plots you’ve combined together. plot_layout() is a patchwork function that lets you set relative plot sizes, decide how to arrange more than 2 plots, and move legends: plot(berry_mfa_res, partial = &quot;all&quot;) + (plot(berry_mfa_res, choix = &quot;var&quot;) + plot(berry_mfa_res, choix = &quot;freq&quot;, invisible = &quot;ind&quot;)) + plot_layout(guides = &quot;collect&quot;, ncol = 1, widths = 2) &amp; theme(plot.title = element_blank(), axis.title = element_blank(), legend.position = &quot;bottom&quot;) If you want to put images anywhere on a visualization, you’re struggling to make a complex arrangement with patchwork, or you have an R list structure containing multiple plots (say, the result of a for loop, *apply(), or nest() call), then cowplot is another option: berry_mfa_res$separate.analyses %&gt;% lapply(function(x) { x$ind$coord %&gt;% as_tibble(rownames = &quot;Berry&quot;) %&gt;% ggplot(aes(x = Dim.1, y = Dim.2)) + geom_point() }) %&gt;% cowplot::plot_grid(plotlist = ., labels = names(.)) #You can also pipe your list into patchwork::wrap_plots() #if you have the latest version of patchwork. #It&#39;s a fairly new package, so it gains big new features very often. Both of these packages can also add letters and other labels to each plot: plot(berry_mfa_res, choix = &quot;var&quot;) + plot(berry_mfa_res, partial = &quot;all&quot;) + plot_layout(guides = &quot;collect&quot;) + plot_annotation(tag_levels = &#39;A&#39;) &amp; theme(plot.title = element_blank(), legend.position = &quot;bottom&quot;) cowplot::plot_grid(plot(berry_mfa_res, choix = &quot;var&quot;), plot(berry_mfa_res, partial = &quot;all&quot;), labels = &quot;AUTO&quot;) #Cowplot doesn&#39;t have a way to combine or move legends. #You&#39;d have to move the legends *before* using plot_grid() If you need to move or realign the labels so they’re not overlapping anything, in patchwork you can add theme(plot.tag.position = c(X, Y)) to individual plots with + or to the whole grouping of plots with &amp;. The cowplot::plot_grid() function has arguments labels_x and labels_y, which let you adjust the distance from the bottom left hand corner of the figure. plot(berry_mfa_res, choix = &quot;var&quot;) + theme(plot.tag.position = c(0.2, 0.95)) + plot(berry_mfa_res, partial = &quot;all&quot;) + theme(plot.tag.position = c(0.12, 0.95)) + plot_layout(guides = &quot;collect&quot;) + plot_annotation(tag_levels = &#39;A&#39;) &amp; theme(plot.title = element_blank(), legend.position = &quot;bottom&quot;) cowplot::plot_grid(plot(berry_mfa_res, choix = &quot;var&quot;), plot(berry_mfa_res, partial = &quot;all&quot;), labels = &quot;AUTO&quot;, label_y = 0.8) You can also use any image editing, publishing, or graphics software to manually combine, arrange, and label plots, but if you need to make changes to a plot later then doing your layout in R will mean you just have to run the lightly-updated code again to re-export a fully formatted multi-part figure, even if the plot dimensions change. 4.6 Finding New Packages This isn’t all the functionality of any of these packages, and these aren’t the only packages that add new features to ggplot2. If you’re trying to figure out how to create a type of plot you’ve never made before, we’d recommend: Ask yourself what variables are represented by the x and y axes, the shapes, the line types, or the colors. Think about whether you can build the plot from smaller components. Is it a grid of scatterplots with colored contour regions? How much of the plot is just points, lines, or rectangles with fancy formatting? You can do a lot with just ggplot2! See if any of the packages in the list of registered ggplot extensions have a plot similar to yours. These packages tend to have very thorough and visual documentation. If it’s a sensory-specific plot, check out the R Opus v2. Almost all of the plots only use ggplot2, patchwork, and ggrepel. Use a web search with the kind of plot you want to make and the keyword “ggplot2” to find tutorials or discussions with example code. Results from Stack Overflow, Data to Viz, or R Graph Gallery are all likely to have good explanations and useful examples, while anything with “(# examples)” in the article name is likely to be very basic material with good SEO. Keep in mind that keywords primarily used in sensory science, say “preference map” or “penalty analysis”, are unlikely to yield examples in ggplot2 with extensive results. In my own process of troubleshooting and double-checking for this workshop, I’ve found some helpful examples by searching “add density contours to 2d scatterplot ggplot” or “ordered bar plot positive and negative ggplot”. Package documentation might come up while you’re looking, but the examples are often very abstract and simple, and they’re often structured around names of functions rather than concepts, so it’s often faster to see some examples of real plots that other people (who aren’t writing an entire R package) wanted to make and then looking up the functions they used to do so. Now, with the rest of the time we have left, I’m going to try and show off how I do some of the most common cleaning-up when it’s time to actually present or publish. "],["fine-tuning-publication-quality-ggplots.html", "5 Fine-Tuning Publication-Quality ggplots 5.1 Exporting and Saving Plots 5.2 Making Text Look Okay 5.3 Removing Legends and Plot Elements 5.4 Ordered Categorical Variables 5.5 Putting it all together", " 5 Fine-Tuning Publication-Quality ggplots The plots we’ve been making so far are fairly straightforward demonstrations. At the very end of Chapter 3, we briefly showed you the code and results for this plot: p1_berry_penalty Which uses some tricks from the stringr and tidytext packages in order to give us easy-to-read labels. Using the existing column names and variable-codes in our original data to make a first draft of a plot, it would’ve looked more like this: berry_penalty_analysis_data %&gt;% select(-count) %&gt;% pivot_wider(names_from = checked, values_from = penalty_lift, names_prefix = &quot;checked_&quot;) %&gt;% mutate(penalty_lift = checked_1 - checked_0) %&gt;% ggplot(mapping = aes(x = cata_variable, y = penalty_lift)) + geom_col(aes(fill = penalty_lift), color = &quot;white&quot;, show.legend = FALSE) + facet_wrap(~berry, scales = &quot;free&quot;, nrow = 2) + coord_flip() + theme_classic() + scale_fill_gradient(low = &quot;tan&quot;, high = &quot;darkgreen&quot;) Which we’re showing because we have seen similar plots published in journal articles, with the overlapping text, redundant axis labels, and all. We can make this more readable by reordering the CATA attributes, shortening and reformatting the labels, and possibly by removing some extraneous elements like the cata_variable label on the Y axis. These are common steps that make a huge difference. And we’ll get there, but first… 5.1 Exporting and Saving Plots It may seem like a weird time to be talking about saving plots, when we haven’t gotten to the “fine-tuning” yet, but you should already be familiar with a few examples of things that change when the aspect ratio of the plot or the monitor you’re viewing it on changes slightly. It is basically impossible to export a ggplot at the resolution needed for publishing without changing the aspect ratio, relative sizes, or space between some elements from what you’re looking at in the Plots pane or the .Rmd chunk output. It’s good practice to export your plot as an image (or pdf or knit-together document or however else you plan to export it) and re-export it periodically as you go through fine-tuning. This is also, probably, the most important part of this chapter. You will have to get every plot that you publish out of R somehow, after all! After that, we’ll cover some tricks that we draw upon frequently, but you may find that you have different problems or priorities, or that some of these needs are situational. But you will have to export plots for every project you want to share with the world. 5.1.1 What format? You can, as we’ve already discussed, save a ggplot object in a .rds file. But that won’t let you put it into your powerpoint, or manuscript, or take it to the printer. You need an image file. The exact type of image will depend on the other software you’re using for your report, presentation, paper, book, etc. There are two major ways to save the kind of spatial color data that comprise images such as graphs. You can store them as vector graphics, which can be rescaled because they’re made up of lines and shapes (most commonly, .pdf and .svg) or as raster (bitmap) graphics, which store images as a grid of pixels which each have a single uniform color (most commonly, .png and .jpeg). .pdf vector images are best for LaTeX and professional publishing .svg vector images are more widely supported in word processors and websites .png raster images are the most predictable to print, the best for web publishing, and can be used in pretty much every software ever made, if you know exactly the size you want. .jpeg (along with .tiff) raster images are the raster format preferred by Food Quality and Preference editors. They are worse for web publishing than .png but share its other advantages. Note that ggsave() is like making a .pdf version of your working documents: you will not be able to read the plot images into R for editing anymore, no matter which format you save in. 5.1.2 Exporting Images with ggsave() The easiest way to reproducibly save plots, so that all of your export options are in your code and you might be able to recreate it on a different computer, is with the function ggplot2::ggsave(), which works similarly to the write_*() functions and save(). You give it a file name to save to, relative to the current working directory, and then the variable where your plot is saved. ggsave(&quot;img/penalty-lift-png.png&quot;, p1_berry_penalty) ggsave() supports all of the above-named image formats, as well as .eps, .ps, .tex (pictex), and .bmp. It will figure out from the file extension (the stuff after the . in the filename argument) what image type it’s saving as, but you can also specify it explicitly with the device argument. If you’re reading this right now, you’re looking at a webpage created using bookdown and knitr. We can’t actually directly embed .pdf images in this site, but let’s look at a few other example formats using the same plots. ggsave(&quot;img/penalty-lift-svg.svg&quot;, p1_berry_penalty) ggsave(&quot;img/penalty-lift-jpeg.jpeg&quot;, p1_berry_penalty) Now let’s compare how each of these looks! First, inside R: p1_berry_penalty # If you&#39;re following along, this will look different in your R session! The .svg image made by ggsave(): The .png image made by ggsave(): The .jpeg image made by ggsave(): The two raster formats look basically the same, and only slightly different from the .svg and the version in the .html version of this tutorial. If you’re following along in your own R session, however, you’ll notice that these saved plots all look more similar to each other than they do to the initial plot you’re previewing inside R. All of the plots have a bit more space around the text using ggsave(), taller bars, and a different aspect ratio (\\(width/height\\)). We can adjust these using the rest of the arguments to ggsave(). The width, height, and units primarily control the image size (for raster images) and aspect ratio (for all images), but they also affect the relative size of plot elements. Larger plots will have axis labels, text, and geom_*()s that take up less of the overall plotting area, and vice-versa for smaller images. If you get to this stage with a vector image and realize that all of the fixed-size elements (e.g., text) are too big or too small, you can use ggsave()’s scale argument. scale &lt; 1 makes all the fixed-size elements smaller relative to the plot size and scale &gt; 1 makes all the elements bigger relative to the plot size. scale &lt; 1 will generally also give you a larger plot area and more space between your geoms. ggsave(&quot;img/penalty-lift-svg-7x4.svg&quot;, p1_berry_penalty, width = 7, height = 4, units = &quot;in&quot;) ggsave(&quot;img/penalty-lift-svg-14x8.svg&quot;, p1_berry_penalty, width = 14, height = 8, units = &quot;in&quot;) ggsave(&quot;img/penalty-lift-svg-14x8-rescale.svg&quot;, p1_berry_penalty, width = 14, height = 8, units = &quot;in&quot;, scale = .5) The 7x4” vector plot: The same plot saved at 14x8”: A 14.8” plot with scale = 0.5: All of these .svg images are displayed at 7x4” on your screen, but the plot we made with width = 14, height = 8 has smaller text and larger plotting areas unless we correct this with scale. penalty-lift-svg-7x4.svg and penalty-lift-svg-14x8-rescale.svg are actually identical files. You should avoid using scale for rasters, as it will create plots that will not print at the size (width and height) and resolution (dpi) you specified. If you find yourself wanting to change the scale of a raster image, you should refer to the reference we’ve put together on dpi in the Appendix. 5.1.3 Other Image Export Options This is not a knitr or bookdown tutorial, because we had to choose our topics, but we used the bookdown package to make the online webpage version of this tutorial. It comes with its own advantages and challenges, but it does significantly streamline the image-generation process for any project where the only file you need is one LaTeX file, .html page, or .pdf output with all of the text and all of the figures. If that sounds appealing to you, turn your attention to “bookdown: Authoring Books and Technical Documents with R Markdown” by Yihui Xie. 5.2 Making Text Look Okay A good R variable or column name doesn’t have any spaces or punctuation other than underscores (_) and dots (.), to avoid all those pesky backticks (```) in our code. This is very different from what a good label in a plot looks like. You’ll often want to make some sort of mass changes to column names or text variables before plotting, in order to address this. 5.2.1 Powerful Text Manipulation with stringr The stringr package is a part of the tidyverse, so you have it already loaded whenever you run library(tidyverse). It has a lot of useful functions for working with text (called “strings” in many programming languages), mostly of the form str_*(). One thing you can do is change labels to uppercase, lowercase, “sentence case”, or “title case” (first letter of each word capitalized), as appropriate: berry_penalty_analysis_data %&gt;% select(berry) %&gt;% mutate(Upper = str_to_upper(berry), Title = str_to_title(berry)) # Capitalizes the first letter of each word ## # A tibble: 170 × 3 ## berry Upper Title ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 blackberry BLACKBERRY Blackberry ## 2 blackberry BLACKBERRY Blackberry ## 3 blackberry BLACKBERRY Blackberry ## 4 blackberry BLACKBERRY Blackberry ## 5 blackberry BLACKBERRY Blackberry ## 6 blackberry BLACKBERRY Blackberry ## 7 blackberry BLACKBERRY Blackberry ## 8 blackberry BLACKBERRY Blackberry ## 9 blackberry BLACKBERRY Blackberry ## 10 blackberry BLACKBERRY Blackberry ## # ℹ 160 more rows str_replace() and str_replace_all() are very useful for dealing with underscores or periods. You give it string, the text vector you want to modify (inside mutate(), a column name); then pattern, the character(s) you want to replace; then replacement, what you want to replace them with. berry_penalty_analysis_data %&gt;% select(-count) %&gt;% pivot_wider(names_from = checked, values_from = penalty_lift, names_prefix = &quot;checked_&quot;) %&gt;% mutate(cata_variable = str_replace_all(cata_variable, &quot;_&quot;, &quot;: &quot;)) ## # A tibble: 85 × 4 ## berry cata_variable checked_0 checked_1 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 blackberry appearance: fresh 4.70 5.80 ## 2 blackberry appearance: goodcolor 4.63 5.77 ## 3 blackberry appearance: goodquality 4.69 5.96 ## 4 blackberry appearance: goodshapre 4.93 5.86 ## 5 blackberry appearance: misshapen 5.63 4.92 ## 6 blackberry appearance: none 5.42 4.78 ## 7 blackberry appearance: notfresh 5.57 3.76 ## 8 blackberry appearance: unevencolor 5.53 4.53 ## 9 blackberry appearane: bruised 5.53 4.67 ## 10 blackberry taste: berry 4.21 6.49 ## # ℹ 75 more rows They can both be as long as you like. If pattern = _ and there’s more than one _ in one of the strings, str_replace() will only replace the first one and str_replace_all() will replace them all. str_replace(&quot;long_text_with_many_underscores&quot;, &quot;_&quot;, &quot; &quot;) ## [1] &quot;long text_with_many_underscores&quot; str_replace_all(&quot;long_text_with_many_underscores&quot;, &quot;_&quot;, &quot; &quot;) ## [1] &quot;long text with many underscores&quot; You can add multiple sets of patterns and replacements to str_replace_all() using a named list: c(\"pattern1\" = \"replace1\", \"pattern2\" = \"replace2\". This is useful to, for instance, fix multiple typos like “goodshapre”. Unlike the case_when() example we showed before, you can fix typos that occur anywhere in the text, even if they’re only parts of a word. berry_penalty_analysis_data %&gt;% select(-count) %&gt;% pivot_wider(names_from = checked, values_from = penalty_lift, names_prefix = &quot;checked_&quot;) %&gt;% mutate(cata_variable = str_replace_all(cata_variable, c(&quot;shapre&quot; = &quot;shape&quot;, &quot;appearane&quot; = &quot;appearance&quot;, &quot;_&quot; = &quot; &quot;))) ## # A tibble: 85 × 4 ## berry cata_variable checked_0 checked_1 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 blackberry appearance fresh 4.70 5.80 ## 2 blackberry appearance goodcolor 4.63 5.77 ## 3 blackberry appearance goodquality 4.69 5.96 ## 4 blackberry appearance goodshape 4.93 5.86 ## 5 blackberry appearance misshapen 5.63 4.92 ## 6 blackberry appearance none 5.42 4.78 ## 7 blackberry appearance notfresh 5.57 3.76 ## 8 blackberry appearance unevencolor 5.53 4.53 ## 9 blackberry appearance bruised 5.53 4.67 ## 10 blackberry taste berry 4.21 6.49 ## # ℹ 75 more rows Be careful using short patterns, because they will replace every example even if it’s only part of a word. #This can lead to unintentional side-effects c(&quot;nocolor&quot;, &quot;none&quot;, &quot;cornonthecob&quot;, &quot;anode&quot;) %&gt;% str_replace_all(&quot;no&quot;, &quot; NO &quot;) ## [1] &quot; NO color&quot; &quot; NO ne&quot; &quot;cor NO nthecob&quot; &quot;a NO de&quot; #Or it can be useful for fixing lots of similar problems all at once berry_penalty_analysis_data %&gt;% select(-count) %&gt;% pivot_wider(names_from = checked, values_from = penalty_lift, names_prefix = &quot;checked_&quot;) %&gt;% mutate(cata_variable = str_replace_all(cata_variable, c(&quot;not&quot; = &quot;not &quot;, &quot;good&quot; = &quot;good &quot;, &quot;uneven&quot; = &quot;uneven &quot;, &quot;_&quot; = &quot; &quot;))) ## # A tibble: 85 × 4 ## berry cata_variable checked_0 checked_1 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 blackberry appearance fresh 4.70 5.80 ## 2 blackberry appearance good color 4.63 5.77 ## 3 blackberry appearance good quality 4.69 5.96 ## 4 blackberry appearance good shapre 4.93 5.86 ## 5 blackberry appearance misshapen 5.63 4.92 ## 6 blackberry appearance none 5.42 4.78 ## 7 blackberry appearance not fresh 5.57 3.76 ## 8 blackberry appearance uneven color 5.53 4.53 ## 9 blackberry appearane bruised 5.53 4.67 ## 10 blackberry taste berry 4.21 6.49 ## # ℹ 75 more rows So far, we’ve been replacing letters and underscores, which is what we have in our example data. You can also use str_replace() for periods (.), although you may be surprised when you first try: str_replace_all(&quot;long.text.with.many.periods&quot;, &quot;.&quot;, &quot; &quot;) # Replaces everything ## [1] &quot; &quot; str_replace_all(&quot;long.text.with.many.periods&quot;, &quot;\\\\.&quot;, &quot; &quot;) # Replaces only dots ## [1] &quot;long text with many periods&quot; We have to escape the period (with an escaped backslash, technically, but for now just know that you must put two backslashes \\\\ before special characters when using stringr). Because the str_* functions with a pattern can use Regular Expressions (or regex), the characters (\\, ., [, ], {, }, (, ), &lt;, &gt;, *, +, -, =, !, ?, ^, $, and |) need to be escaped with two backslashes if you need to replace them. Regex are extremely powerful tools for finding patterns in text, similar to the intuitive ways a human might recognize something like an email address, a measurement, or a parenthetical. We will not be talking about regex today, but if you want to see some examples and resources for learning how to use them, we’ve provided a short overview and links to some resources in the Appendix. 5.3 Removing Legends and Plot Elements You’ve already seen us use + theme(panel.grid = element_blank()) to get rid of the grid lines in a plot. You can use element_blank() to get rid of lots of plot elements you might not want for whatever reason, usually because it’s redundant with information you have elsewhere and thus just making the plot look more complicated or harder to read at a glance. The most common things you might want to remove are: plot.title, if some function added a title to the top of your plot and you want to get rid of it. axis.title, axis.title.x, or axis.title.y if you don’t need the column name(s) labeling your axes axis.ticks, axis.ticks.x, or axis.ticks.y if you want to remove the little tick marks along a given axis (useful for bar plots) berry_long_liking %&gt;% ggplot(aes(x = Scale, y = Liking, color = Scale)) + ggbeeswarm::geom_quasirandom() + facet_wrap(~ Attribute) + theme_bw() + theme(panel.grid = element_blank(), axis.ticks = element_blank(), legend.position = &quot;none&quot;) You can see a nearly-full list of the arguments to ggplot2::theme() in the theme help files (?theme), unlike with ggplot2 aesthetics and the geom_*() help files. If you want to remove the legend, you use + theme(legend.position = \"none\"), but if you want to remove specific geoms from the legend, then you have to adjust your geom_*() calls. ca_cider$col$coord %&gt;% as_tibble(rownames = &quot;Attribute&quot;) %&gt;% mutate(Modality = case_when(Attribute == &quot;Sweet&quot; ~ &quot;Taste&quot;, Attribute == &quot;Bitter&quot; ~ &quot;Taste&quot;, Attribute == &quot;Sour&quot; ~ &quot;Taste&quot;, Attribute == &quot;Smooth&quot; ~ &quot;Mouthfeel&quot;, Attribute == &quot;Dry&quot; ~ &quot;Mouthfeel&quot;, Attribute == &quot;FullBodied&quot; ~ &quot;Mouthfeel&quot;, .default = &quot;Aroma&quot;)) %&gt;% ggplot(aes(x = `Dim 1`, y = `Dim 2`, label = Attribute, color = Modality)) -&gt; ca_cider_colored ca_cider_colored + geom_point() + ggrepel::geom_text_repel() ca_cider_colored + geom_point() + ggrepel::geom_text_repel(show.legend = FALSE) 5.4 Ordered Categorical Variables Many of the figures we’ve made so far have had one axis with a categorical variable. Have you figured out how ggplot2 orders the levels of categorical variables? If you have noticed, it’s likely because it’s in a different order than the one we’d like. long_cider_data %&gt;% filter(checked == 1) %&gt;% ggplot(aes(x = cata_variable)) + geom_bar() + coord_flip() + facet_grid(vars(Temperature), vars(Sample_Name)) The CATA attributes are in alphabetical order. This is how ggplot2 treats all character variables, and you can exert some control over the ordering by turning the variable into an ordered factor. 5.4.1 Specifying Ordinal Variables as Factors You can order variables by hand, if there’s a particular order you have in mind: long_cider_data %&gt;% mutate(cata_variable = factor(cata_variable, levels = c(&quot;Sweet&quot;, &quot;Sour&quot;, &quot;Bitter&quot;, &quot;Smooth&quot;, &quot;Dry&quot;, &quot;FullBodied&quot;, &quot;Light&quot;, &quot;Fruity&quot;, &quot;Berries&quot;, &quot;Fresh_Apples&quot;, &quot;Floral&quot;, &quot;Spice&quot;, &quot;Herbal&quot;, &quot;Woody&quot;, &quot;Earthy&quot;, &quot;Funky&quot;, &quot;Fermented&quot;, &quot;Vomit&quot;, &quot;Synthetic&quot;, &quot;Candy&quot;, &quot;Metallic&quot;, &quot;Alcohol&quot;))) -&gt; long_cider_manual_factors long_cider_manual_factors %&gt;% filter(checked == 1) %&gt;% ggplot(aes(x = cata_variable)) + geom_bar() + coord_flip() + facet_grid(vars(Temperature), vars(Sample_Name)) Note that the attribute you list first when you’re specifying the levels will become 1, then 2, then 3. With coord_flip(), that puts it at the bottom of the plot. long_cider_manual_factors %&gt;% distinct(cata_variable) %&gt;% mutate(variable_number = as.numeric(cata_variable)) ## # A tibble: 22 × 2 ## cata_variable variable_number ## &lt;fct&gt; &lt;dbl&gt; ## 1 Fresh_Apples 10 ## 2 Fermented 17 ## 3 Herbal 13 ## 4 Dry 5 ## 5 Spice 12 ## 6 Fruity 8 ## 7 Smooth 4 ## 8 Alcohol 22 ## 9 Light 7 ## 10 Sweet 1 ## # ℹ 12 more rows This gives us control, but it’s pretty annoying to write out for large lists of attributes, and you have to be sure the spelling and capitalization match exactly. Often, like with the penalty analysis plots, what we actually want to do is order the Attributes in terms of some other numerical variable, like frequency or size of penalty. One way is to arrange() the data the way you want it and then use that order to specify the levels. long_cider_data %&gt;% # Counting the number of times each attribute is used across all products: group_by(cata_variable) %&gt;% mutate(variable_count = sum(checked)) %&gt;% ungroup() %&gt;% # Arranging from least-to-most used: arrange(variable_count) %&gt;% # Converting to a factor, so the least-used will be 1st, then the next: mutate(cata_variable = factor(cata_variable, levels = unique(cata_variable), ordered = TRUE), variable_number = as.numeric(cata_variable)) -&gt; long_cider_frequency_factors #Now the plot: long_cider_frequency_factors %&gt;% filter(checked == 1) %&gt;% ggplot(aes(x = cata_variable)) + geom_bar() + coord_flip() + facet_grid(vars(Temperature), vars(Sample_Name)) 5.4.2 Facets with Different Category-Orders You’ll notice that our reordered categorical axes still have the same order across all of the plots. This would be true even if we changed our group_by() call and used within-product sums to calculate levels. The order is based on factor levels for a single column, and Fresh_Apples can’t be “more than” Dry in one part of the column and “less than” in another part. On its own, facet_wrap(..., scales = \"free\") can drop unneeded attributes from plots, but it will still keep the same order of the attributes across all axes. If you have a faceted plot and you want each facet to have a different ordering of the terms, like in our big penalty analysis example, you’ll have to use tidytext::reorder_within(), tidytext::scale_*_reordered(), and facet_wrap(..., scales = \"free\"), all at once: long_cider_data %&gt;% # Counting the number of times each attribute is used across all products: group_by(Sample_Name, Temperature, cata_variable) %&gt;% mutate(Product = str_c(Sample_Name, &quot; (&quot;, Temperature, &quot;)&quot;), variable_count = sum(checked), cata_variable = tidytext::reorder_within(cata_variable, by = variable_count, within = list(Sample_Name, Temperature))) %&gt;% ungroup() %&gt;% filter(checked == 1) %&gt;% ggplot(aes(x = cata_variable)) + geom_bar() + tidytext::scale_x_reordered() + coord_flip() + # This will not work with facet_grid, because it forces all plots in a row to # share a vertical axis, even with scales = &quot;free&quot; facet_wrap(~ Product, scales = &quot;free&quot;) 5.5 Putting it all together Now, at long last, we’re ready to walk line-by-line through the example penalty analysis figure that we’ve just been copy-pasting so far in the workshop. berry_penalty_analysis_data %&gt;% select(-count) %&gt;% pivot_wider(names_from = checked, values_from = penalty_lift, names_prefix = &quot;checked_&quot;) %&gt;% separate(cata_variable, into = c(&quot;mode&quot;, &quot;variable&quot;), sep = &quot;_&quot;) %&gt;% mutate(penalty_lift = checked_1 - checked_0, mode = case_when(mode == &quot;taste&quot; ~ &quot;(T)&quot;, mode == &quot;appearance&quot; ~ &quot;(A)&quot;, mode == &quot;appearane&quot; ~ &quot;(A)&quot;)) %&gt;% unite(variable, mode, col = &quot;cata_variable&quot;, sep = &quot; &quot;) %&gt;% mutate(cata_variable = tidytext::reorder_within(x = cata_variable, by = penalty_lift, within = berry)) %&gt;% ggplot(mapping = aes(x = cata_variable, y = penalty_lift)) + geom_col(aes(fill = penalty_lift), color = &quot;white&quot;, show.legend = FALSE) + facet_wrap(~berry, scales = &quot;free&quot;, nrow = 1) + tidytext::scale_x_reordered() + coord_flip() + theme_classic() + scale_fill_gradient(low = &quot;tan&quot;, high = &quot;darkgreen&quot;) + labs(x = NULL, y = NULL, title = &quot;Penalty / Lift Analysis&quot;, subtitle = &quot;displays the mean difference (within berries) for when a CATA variable is checked\\nor un-checked&quot;) "],["wrap-up-and-further-resources.html", "6 Wrap-up and further resources 6.1 Getting help 6.2 Further reading/resources 6.3 Questions/Comments 6.4 References", " 6 Wrap-up and further resources Let’s look back at what we were aiming to do today: In this tutorial, we will introduce the audience to ggplot2 and the rest of the tidyverse R packages with the aim of developing sufficient basic skills to visualize multivariate sensory and consumer data. We will provide a learning dataset for the analysis—a set of free response comments and overall liking scores from a central location test on berries. We will teach participants how to import, manipulate, and plot data using user-friendly, “tidy” R programming. All resources used in the tutorial are open-source and will remain available to attendees, including an R script covering the full workflow. At the end of the tutorial, attendees will be able to prepare raw sensory data for common multivariate visual representations in R. We have managed to touch on all of these topics, but of course we have taken the most cursory look at each. I hope what we’ve gone over today has inspired you, sure, but I mostly hope it has shown you how much you can do with just a little knowledge. My journey in terms of learning data science with R has been all about building my coding ability incrementally. My code looks more like this than anything else, but I am able to get so much done: What does good code even look like? (via XKCD) By developing your ability to code (in R or Python, or whatever works for you–Julia?) you will open up a whole set of analyses that you would otherwise be unable to access. 6.1 Getting help Look up the help file for whatever you’re doing. Do this by using the syntax ?&lt;search item&gt; (for example ?c gets help on the vector command) as a shortcut on the console. Search the help files for a term you think is related. Can’t remember the command for making a sequence of integers? Go to the “Help” pane in RStudio and search in the search box for “sequence”. See if some of the top results get you what you need. The internet. Seriously. I am not kidding even a little bit. R has one of the most active and (surprisingly) helpful user communities I’ve ever encountered. Try going to google and searching for “How do I make a sequence of numbers in R?” You will find quite a bit of useful help. I find the following sites particularly helpful Stack Overflow Cross Validated/Stack Exchange Seriously, Google will get you most of the way to helpful answers for many basic R questions. I want to emphasize that looking up help is normal. I do it all the time. Learning to ask questions in helpful ways, how to quickly parse the information you find, and how to slightly alter the answers to suit your particular situation are key skills. 6.2 Further reading/resources General R programming Data Carpentry’s R for Social Scientists (and, really the courses from The Carpentries in general) Wickham &amp; Grolemund’s R for Data Science The stat545 course website My own (somewhat opinionated and eccentric) course from VT: FST 5984 Data Visualization Best Practices Healy’s Data Visualization “Caveats” from the website Data to Viz, including topics such as why radar plots &amp; pie charts are controversial and what to use instead. ggplot2-specific Winston Chang’s R Graphics Cookbook, basically a collection of short tips and sample plots R Graph Gallery’s posts breaking down the code to make real, complex, polished ggplots ggplot2’s registered extension gallery We will also be presenting… 6.3 Questions/Comments If you get stuck, feel free to find us during the conference, or email us at jlahne at vt dot edu and lhamilton at vsu dot edu. I’d love to learn about what you’re working on! 6.4 References "],["appendix.html", "Appendix Image Sizes and Raster Resolutions Regular Expressions", " Appendix Image Sizes and Raster Resolutions Simpler Sizing: Vector Images You might be surprised that vector images have height and width options, because we said they don’t have a fixed display size, but as you saw in Chapter 5, ggsave() picked a default image size of 7x7 inches when we didn’t specify. The height and width are mostly important for determining the relative sizing of elements like text and whitespace. ggplot2 actually saves the sizes of certain plot elements, namely text and most geom_*()s, in inches or millimeters. When it has to construct an actual version of the plot at a given size, it tries to keep all of the 12-pt text 1/6” tall (1 inch = 72 points). This 12-point font will take up a very small amount of a 4-foot-tall image, but a sixth of a 1” image. The fact that you can then print the .svg at any size you want is out of ggplot2’s hands. It will try to make the fonts and elements the right size for the size you’re telling it you will print. This means that the scale argument of ggsave(), for vectors, can just change the output size as long as you keep the same aspect ratio. It doesn’t change the number of points per inch, and it doesn’t change the point-size of any fonts or other elements in the plot. It’s easier to just print a different size figure. If you try to use this same trick for raster images, your picture will not be \\(width \\times dpi\\) pixels wide. This has flummoxed many a researcher trying to export very large, crisp figures for a poster. Raster Image Resolutions All raster images are made up of grids of dots or pixels. Once you export a figure from R as a .png, .jpeg, or other raster format, you cannot resize it. It will look blurry or blocky if you try to make it bigger, and even slight changes to the aspect ratio (\\(width/height\\)), the text and other plot elements will be noticeably stretched out. You’ll have fewer problems if you save an image that’s way too big (i.e., has too many pixels) for what you need, so long as it’s the right aspect ratio and all the plot elements have relative sizes that work at the scale you’ll be printing. (See this short primer on “Using R Plots in Documents” from the University of Wisconsin-Madison for examples.) So, how big is a pixel? How many pixels are in an inch? It depends! (On the pixel density for screens and the resolution for printing, see the discussion on this page for details.) Most modern computer monitors have something like 90-120 pixels per inch (ppi) Microsoft Powerpoint uses an internal resolution of 96 ppi as a default, although images will print at more than 96 dpi if they’re sized appropriately. Older Apple software has a default of 72 ppi ggsave() uses a default of 300 dpi Poster printers will usually print at 300 dots per inch (dpi). They may ask for a minimum resolution of anywhere between 120-300 dpi, although 300 dpi will usually be a safe bet. Use your specific printer’s recommendations. Elsevier journals like Food Quality and Preference suggest at least 300 dpi for all images and at least 500 dpi for “combination art”, which includes all R plots with colored or shaded areas. This is important because, if you have a 600x600-pixel raster image, and you try to print it any bigger than 2 inches x 2 inches on a 300 dpi printer, then you have missing image data and the printed version will look blurry. Whenever something, like a design software or an R function to save a plot, gives you the chance to enter an image size in inches or centimeters, you should figure out what dpi or ppi it’s using. It may be easier to figure out the final pixel size you want and export something that size or bigger. (For more details, see this guide on “Preparing Images for PowerPoint, the Web, and Publication” from the University of Michigan. It’s slightly outdated, so ignore the specific dpi/ppi numbers.) You can see the possible image widths and corresponding pixel sizes for Elsevier journals here. For PowerPoint presentations, assume you’re filling a 13.3x7.5” space at 150 dpi. For printed posters, you’ll find the final poster size on the competition guidelines and the final resolution from your printer. 12”x12” for a single figure at 300 dpi is a good place to start. You will almost certainly have to re-export your figures several times in order to get the sizing and aspect ratios right. Let’s save a the same plots as a raster image (.png) with a few different dpi values. ggsave(&quot;img/penalty-lift-png-50dpi.png&quot;, p1_berry_penalty, width = 7, height = 4, units = &quot;in&quot;, dpi = 50) ggsave(&quot;img/penalty-lift-png-300dpi.png&quot;, p1_berry_penalty, width = 7, height = 4, units = &quot;in&quot;) #default dpi = 300 ggsave(&quot;img/penalty-lift-png-500dpi.png&quot;, p1_berry_penalty, width = 7, height = 4, units = &quot;in&quot;, dpi = 500) 7x4” at 50 dpi: 7x4” at 300 dpi (the ggsave() default): 7x4” at 500 dpi: You can see that all of the 7x4” raster plots look basically the same, except the first one is a little blurry when it’s sized up to match the other two on your probably ~100 dpi monitor. This is the problem we’re trying to avoid. Unlike scale, the dpi argument does not resize any of the text or geoms (it doesn’t change the size of a “point” from 1/72”). But let’s say we need a 300 dpi copy of this image printed at 14x8”. We already know that the 14x8” output has text that’s too small to read from afar. In cases like these, it may be easier to output a size with the right aspect ratio that looks good and is legible, then figure out what dpi you’ll need to print it. If we need a 14x8” plot at 300 dpi, that’s \\(14 \\times 300 = 4200\\) pixels wide by \\(8 \\times 300 = 2400\\) tall. We can fake this with our 7x4” plot at 600 dpi, since \\(4200 / 7 = 600\\) and \\(2400 / 4 = 600\\). Regular Expressions A regular expression, or regex, is a way of compactly writing a pattern that will let you match similarly-structured pieces of text. You may use regex because you want the list of matches itself, because you want to do something to pieces of text with a certain pattern somewhere in them, or because you want to replace all matches with something else. Regex were originally designed in the 1980s, and are also a central part of the design of the stringr package (although stringr still has a lot of useful tools without them). If you wanted to match all words ending in “ly”, you could use \\\\b\\\\w+ly\\\\b, which looks for a word boundary (\\\\b), followed by at least one (+) “word character” (\\\\w, mostly letters), followed by the letters “ly”, followed by another word boundary. You can use a similar regex to find all integers (\\\\b\\\\d+\\\\b) or expand it to find integers and numbers with a decimal (\\\\b\\\\d+(\\\\.\\\\d+)?\\\\b). Mostly, Regex are very powerful and very difficult to read. We’ll provide a few semi-realistic examples in action to show off just how powerful they can be, and just how messy they look: str_extract(&quot;If you want to get in touch with me you can do so at lhamilton@vsu.edu.&quot;, &quot;\\\\w*@\\\\w+\\\\.(edu|gov|com|org|biz|net|fr|co\\\\.uk)\\\\b&quot;) ## [1] &quot;lhamilton@vsu.edu&quot; str_extract_all(&quot;Our 300th measurement was 10.31 cm, our 301st clocked in at 3.213in&quot;, &quot;\\\\d+\\\\.\\\\d+ ?(cm|in|m)&quot;) ## [[1]] ## [1] &quot;10.31 cm&quot; &quot;3.213in&quot; str_extract_all(&quot;Regular Expressions (regex) are one tool in Natural Language Processing (NLP)&quot;, &quot;(?&lt;=\\\\()[^)]*(?=\\\\))&quot;) ## [[1]] ## [1] &quot;regex&quot; &quot;NLP&quot; You can try changing the searched string in the above code to see if it recognizes your email or how many numbers you can get it to recognize. Usually, though, your plot labels aren’t in full sentences in your data frame. Simpler regular expressions can still save you a lot of work. Without regular expressions, our main penalty analysis example has to separate() the CATA variable names into two parts, use a case_when() to individually match the modalities to a cleaned-up “(A)” or “(T)”, and then finally unite() them back into one column: berry_penalty_analysis_data %&gt;% select(-count) %&gt;% pivot_wider(names_from = checked, values_from = penalty_lift, names_prefix = &quot;checked_&quot;) %&gt;% separate(cata_variable, into = c(&quot;mode&quot;, &quot;variable&quot;), sep = &quot;_&quot;) %&gt;% mutate(mode = case_when(mode == &quot;taste&quot; ~ &quot;(T)&quot;, mode == &quot;appearance&quot; ~ &quot;(A)&quot;, mode == &quot;appearane&quot; ~ &quot;(A)&quot;)) %&gt;% unite(variable, mode, col = &quot;cata_variable&quot;, sep = &quot; &quot;) ## # A tibble: 85 × 4 ## berry cata_variable checked_0 checked_1 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 blackberry fresh (A) 4.70 5.80 ## 2 blackberry goodcolor (A) 4.63 5.77 ## 3 blackberry goodquality (A) 4.69 5.96 ## 4 blackberry goodshapre (A) 4.93 5.86 ## 5 blackberry misshapen (A) 5.63 4.92 ## 6 blackberry none (A) 5.42 4.78 ## 7 blackberry notfresh (A) 5.57 3.76 ## 8 blackberry unevencolor (A) 5.53 4.53 ## 9 blackberry bruised (A) 5.53 4.67 ## 10 blackberry berry (T) 4.21 6.49 ## # ℹ 75 more rows With regular expressions, you can combine all of this in one step: berry_penalty_analysis_data %&gt;% select(-count) %&gt;% pivot_wider(names_from = checked, values_from = penalty_lift, names_prefix = &quot;checked_&quot;) %&gt;% mutate(cata_variable = str_replace(cata_variable, &quot;^(.).*_(.*)&quot;, &quot;\\\\2 (\\\\1)&quot;), cata_variable = str_to_title(cata_variable)) ## # A tibble: 85 × 4 ## berry cata_variable checked_0 checked_1 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 blackberry Fresh (A) 4.70 5.80 ## 2 blackberry Goodcolor (A) 4.63 5.77 ## 3 blackberry Goodquality (A) 4.69 5.96 ## 4 blackberry Goodshapre (A) 4.93 5.86 ## 5 blackberry Misshapen (A) 5.63 4.92 ## 6 blackberry None (A) 5.42 4.78 ## 7 blackberry Notfresh (A) 5.57 3.76 ## 8 blackberry Unevencolor (A) 5.53 4.53 ## 9 blackberry Bruised (A) 5.53 4.67 ## 10 blackberry Berry (T) 4.21 6.49 ## # ℹ 75 more rows And you can even go farther by combining multiple replacements (for typos, for adding in spaces, etc) in one call to str_replace_all(). berry_penalty_analysis_data %&gt;% select(-count) %&gt;% pivot_wider(names_from = checked, values_from = penalty_lift, names_prefix = &quot;checked_&quot;) %&gt;% mutate(cata_variable = str_replace_all(cata_variable, c(&quot;^(.).*_(.*)&quot; = &quot;\\\\2 (\\\\1)&quot;, &quot;good&quot; = &quot;good &quot;, &quot;not&quot; = &quot;not &quot;, &quot;shapre&quot; = &quot;shape&quot;, &quot;uneven&quot; = &quot;uneven &quot;)), cata_variable = str_to_title(cata_variable)) ## # A tibble: 85 × 4 ## berry cata_variable checked_0 checked_1 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 blackberry Fresh (A) 4.70 5.80 ## 2 blackberry Good Color (A) 4.63 5.77 ## 3 blackberry Good Quality (A) 4.69 5.96 ## 4 blackberry Good Shape (A) 4.93 5.86 ## 5 blackberry Misshapen (A) 5.63 4.92 ## 6 blackberry None (A) 5.42 4.78 ## 7 blackberry Not Fresh (A) 5.57 3.76 ## 8 blackberry Uneven Color (A) 5.53 4.53 ## 9 blackberry Bruised (A) 5.53 4.67 ## 10 blackberry Berry (T) 4.21 6.49 ## # ℹ 75 more rows You do not have to learn regular expressions to clean up messy text, but being comfortable with them will (eventually) make you faster. You should at least learn the characters (\\, ., [, ], {, }, (, ), &lt;, &gt;, *, +, -, =, !, ?, ^, $, and |) that will need to be escaped with two backslashes if you need to replace them. It will help you troubleshoot any weird results you get from the str_*() functions. If you want to learn more, we’d recommend starting with the stringr package’s own vignette on regular expressions, which you can view with vignette(\"regular-expressions\", \"stringr\"). If you want more practice, you can then follow along with the RegexOne tutorial or RegexTutorials. Any “perl-flavored” regex tutorial or resource will work, with the exception that you will have to double the number of backslashes (\\) to use them in R. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
